{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "test on a simple case\n",
    "\\Omega is the unit circle\n",
    "\\delta u = 1 \n",
    "u=0 at border of \\Omega\n",
    "u=1/4*(x^2+y^2)-1/4\n",
    "'''\n",
    "\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "m=10\n",
    "learning_rate=1e-2  \n",
    "iterations=8000  #default 10000\n",
    "print_every_iter=100\n",
    "beta=500 #coefficient for the regularization term in the loss expression, is set to be 1000 in section 3.1\n",
    "n1=500 #number of points in (0,1)^m\n",
    "n2=100  #number of points on the border of (0,1)^m\n",
    "n3=100  #number of points used for evaluating the error\n",
    "\n",
    "class DeepRitzNet(torch.nn.Module):\n",
    "    def __init__(self, m):\n",
    "        super(DeepRitzNet, self).__init__()\n",
    "        self.linear1=torch.nn.Linear(m,m)\n",
    "        self.linear2=torch.nn.Linear(m,m)\n",
    "        self.linear3=torch.nn.Linear(m,m)\n",
    "        self.linear4=torch.nn.Linear(m,m)\n",
    "        self.linear5=torch.nn.Linear(m,m)\n",
    "        self.linear6=torch.nn.Linear(m,m)\n",
    "        \n",
    "        self.linear7=torch.nn.Linear(m,1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y=(F.relu(self.linear1(x)))**3\n",
    "        y=(F.relu(self.linear2(x)))**3\n",
    "        y+=x\n",
    "        x=y\n",
    "        y=(F.relu(self.linear3(x)))**3\n",
    "        y=(F.relu(self.linear4(x)))**3\n",
    "        y+=x\n",
    "        x=y\n",
    "        y=(F.relu(self.linear5(x)))**3\n",
    "        y=(F.relu(self.linear6(x)))**3\n",
    "        y+=x\n",
    "        y=(F.relu(self.linear7(x)))**3\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#U_groundtruth = 1/4*(x^2+y^2)-1/4\n",
    "#take in a (m,) tensor (x, y, ...)\n",
    "def U_groundtruth(t):\n",
    "    re = (t[0]**2 + t[1]**2 - 1).item()/4\n",
    "    return re\n",
    "\n",
    "#turn a (2,) tensor/ndarray to a (m,) tensor\n",
    "def zeropad(x_2):\n",
    "    x_10=torch.zeros(m,)\n",
    "    x_10[0]=x_2[0]\n",
    "    x_10[1]=x_2[1]\n",
    "    return x_10\n",
    "    \n",
    "#sample a (m,) tensor on the border of the unit circle\n",
    "def on_sample():\n",
    "    theta=np.random.rand()*2*math.pi\n",
    "    re=np.zeros(m)\n",
    "    re[0]=math.cos(theta)\n",
    "    re[1]=math.sin(theta)\n",
    "    re=torch.tensor(re,requires_grad=True)\n",
    "    return re\n",
    "\n",
    "#sample a (m,) tensor in the unit circle\n",
    "def in_sample():\n",
    "    r=np.random.rand()\n",
    "    theta=np.random.rand()*2*math.pi\n",
    "    re=np.zeros(m)\n",
    "    re[0]=r*math.cos(theta)\n",
    "    re[1]=r*math.sin(theta)\n",
    "    re=torch.tensor(re,requires_grad=True)\n",
    "    return re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at the 100 th iteration: tensor(1.00000e-04 *\n",
      "       [ 2.1304])\n",
      "Error in Omega at the 100 th iteration: 0.2500043511390686\n",
      "Error on the border of Omega at the 100 th iteration: 0.001980452099815011\n",
      "Loss at the 200 th iteration: tensor(1.00000e-05 *\n",
      "       [ 3.0990])\n",
      "Error in Omega at the 200 th iteration: 0.2499949187040329\n",
      "Error on the border of Omega at the 200 th iteration: 0.0013210027245804667\n",
      "Loss at the 300 th iteration: tensor(1.00000e-05 *\n",
      "       [ 4.1320])\n",
      "Error in Omega at the 300 th iteration: 0.2499893307685852\n",
      "Error on the border of Omega at the 300 th iteration: 0.0010581110836938024\n",
      "Loss at the 400 th iteration: tensor(1.00000e-05 *\n",
      "       [ 3.2764])\n",
      "Error in Omega at the 400 th iteration: 0.2499977946281433\n",
      "Error on the border of Omega at the 400 th iteration: 0.0009002292645163834\n",
      "Loss at the 500 th iteration: tensor(1.00000e-06 *\n",
      "       [ 6.2391])\n",
      "Error in Omega at the 500 th iteration: 0.25000038743019104\n",
      "Error on the border of Omega at the 500 th iteration: 0.000814214232377708\n",
      "Loss at the 600 th iteration: tensor(1.00000e-06 *\n",
      "       [-3.3409])\n",
      "Error in Omega at the 600 th iteration: 0.24999409914016724\n",
      "Error on the border of Omega at the 600 th iteration: 0.0007330079097300768\n",
      "Loss at the 700 th iteration: tensor(1.00000e-06 *\n",
      "       [ 5.6162])\n",
      "Error in Omega at the 700 th iteration: 0.249980628490448\n",
      "Error on the border of Omega at the 700 th iteration: 0.0006931645912118256\n",
      "Loss at the 800 th iteration: tensor(1.00000e-05 *\n",
      "       [-1.4090])\n",
      "Error in Omega at the 800 th iteration: 0.2499690055847168\n",
      "Error on the border of Omega at the 800 th iteration: 0.000656253716442734\n",
      "Loss at the 900 th iteration: tensor(1.00000e-05 *\n",
      "       [-2.5058])\n",
      "Error in Omega at the 900 th iteration: 0.24999995529651642\n",
      "Error on the border of Omega at the 900 th iteration: 0.0006274227635003626\n",
      "Loss at the 1000 th iteration: tensor(1.00000e-06 *\n",
      "       [-6.8683])\n",
      "Error in Omega at the 1000 th iteration: 0.24999909102916718\n",
      "Error on the border of Omega at the 1000 th iteration: 0.0006002306472510099\n",
      "Loss at the 1100 th iteration: tensor(1.00000e-06 *\n",
      "       [-8.2740])\n",
      "Error in Omega at the 1100 th iteration: 0.24995213747024536\n",
      "Error on the border of Omega at the 1100 th iteration: 0.000587484217248857\n",
      "Loss at the 1200 th iteration: tensor(1.00000e-05 *\n",
      "       [-1.5919])\n",
      "Error in Omega at the 1200 th iteration: 0.2499852031469345\n",
      "Error on the border of Omega at the 1200 th iteration: 0.0005666278302669525\n",
      "Loss at the 1300 th iteration: tensor(1.00000e-05 *\n",
      "       [-1.2583])\n",
      "Error in Omega at the 1300 th iteration: 0.24999970197677612\n",
      "Error on the border of Omega at the 1300 th iteration: 0.0005558699485845864\n",
      "Loss at the 1400 th iteration: tensor(1.00000e-06 *\n",
      "       [-5.8341])\n",
      "Error in Omega at the 1400 th iteration: 0.24999935925006866\n",
      "Error on the border of Omega at the 1400 th iteration: 0.0005413559847511351\n",
      "Loss at the 1500 th iteration: tensor(1.00000e-06 *\n",
      "       [-9.6071])\n",
      "Error in Omega at the 1500 th iteration: 0.24988648295402527\n",
      "Error on the border of Omega at the 1500 th iteration: 0.0005344088422134519\n",
      "Loss at the 1600 th iteration: tensor(1.00000e-06 *\n",
      "       [ 1.2933])\n",
      "Error in Omega at the 1600 th iteration: 0.2497367262840271\n",
      "Error on the border of Omega at the 1600 th iteration: 0.0005238886806182563\n",
      "Loss at the 1700 th iteration: tensor(1.00000e-05 *\n",
      "       [-2.3052])\n",
      "Error in Omega at the 1700 th iteration: 0.24999873340129852\n",
      "Error on the border of Omega at the 1700 th iteration: 0.0005202997708693147\n",
      "Loss at the 1800 th iteration: tensor(1.00000e-06 *\n",
      "       [-9.7455])\n",
      "Error in Omega at the 1800 th iteration: 0.2500000298023224\n",
      "Error on the border of Omega at the 1800 th iteration: 0.0005115436506457627\n",
      "Loss at the 1900 th iteration: tensor(1.00000e-05 *\n",
      "       [-1.1911])\n",
      "Error in Omega at the 1900 th iteration: 0.2499859780073166\n",
      "Error on the border of Omega at the 1900 th iteration: 0.000508649623952806\n",
      "Loss at the 2000 th iteration: tensor(1.00000e-05 *\n",
      "       [-1.0472])\n",
      "Error in Omega at the 2000 th iteration: 0.24999591708183289\n",
      "Error on the border of Omega at the 2000 th iteration: 0.0005049587343819439\n",
      "Loss at the 2100 th iteration: tensor(1.00000e-05 *\n",
      "       [-1.1077])\n",
      "Error in Omega at the 2100 th iteration: 0.2499692291021347\n",
      "Error on the border of Omega at the 2100 th iteration: 0.0005012841429561377\n",
      "Loss at the 2200 th iteration: tensor(1.00000e-06 *\n",
      "       [-8.5238])\n",
      "Error in Omega at the 2200 th iteration: 0.2500001788139343\n",
      "Error on the border of Omega at the 2200 th iteration: 0.0004963412065990269\n",
      "Loss at the 2300 th iteration: tensor(1.00000e-06 *\n",
      "       [-8.1664])\n",
      "Error in Omega at the 2300 th iteration: 0.24969062209129333\n",
      "Error on the border of Omega at the 2300 th iteration: 0.0004960285150445998\n",
      "Loss at the 2400 th iteration: tensor(1.00000e-06 *\n",
      "       [-3.3926])\n",
      "Error in Omega at the 2400 th iteration: 0.24989166855812073\n",
      "Error on the border of Omega at the 2400 th iteration: 0.0004977567587047815\n",
      "Loss at the 2500 th iteration: tensor(1.00000e-06 *\n",
      "       [-9.0912])\n",
      "Error in Omega at the 2500 th iteration: 0.24999675154685974\n",
      "Error on the border of Omega at the 2500 th iteration: 0.0004955093609169126\n",
      "Loss at the 2600 th iteration: tensor(1.00000e-05 *\n",
      "       [-1.1238])\n",
      "Error in Omega at the 2600 th iteration: 0.2499784529209137\n",
      "Error on the border of Omega at the 2600 th iteration: 0.000492822437081486\n",
      "Loss at the 2700 th iteration: tensor(1.00000e-05 *\n",
      "       [-1.8348])\n",
      "Error in Omega at the 2700 th iteration: 0.2499958574771881\n",
      "Error on the border of Omega at the 2700 th iteration: 0.000493569066748023\n",
      "Loss at the 2800 th iteration: tensor(1.00000e-06 *\n",
      "       [-7.9599])\n",
      "Error in Omega at the 2800 th iteration: 0.24998238682746887\n",
      "Error on the border of Omega at the 2800 th iteration: 0.0004939422942698002\n",
      "Loss at the 2900 th iteration: tensor(1.00000e-06 *\n",
      "       [-9.4049])\n",
      "Error in Omega at the 2900 th iteration: 0.24996758997440338\n",
      "Error on the border of Omega at the 2900 th iteration: 0.0004946963163092732\n",
      "Loss at the 3000 th iteration: tensor(1.00000e-06 *\n",
      "       [-9.6755])\n",
      "Error in Omega at the 3000 th iteration: 0.2499016970396042\n",
      "Error on the border of Omega at the 3000 th iteration: 0.0004941855440847576\n"
     ]
    }
   ],
   "source": [
    "model = DeepRitzNet(m)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "in_error_iter=[] #record the error in Omega every print_every_iter=100 times\n",
    "on_error_iter=[] #record the error on the border of Omega every print_every_iter=100 times\n",
    "\n",
    "for i in range(iterations):\n",
    "    #calculate the loss \n",
    "    loss=torch.zeros(1)\n",
    "    for t in range(n1):\n",
    "        #if I miss out the \".float()\" there will be an error and I don't know why\n",
    "        #It seems to have something to do with the usage of relu()**3 in DeepRitzNet\n",
    "        x_input=in_sample()\n",
    "        y=model(x_input.float())\n",
    "        #there will be an error without \"retain_graph=True\" , I don't know why\n",
    "        y.backward(retain_graph=True)\n",
    "        loss+=0.5*((x_input.grad.float()[0])**2+(x_input.grad.float()[1])**2)-y      \n",
    "        #print(x_input.grad.float())##for checking\n",
    "    loss/=n1\n",
    "    \n",
    "    regularization=torch.zeros(1)\n",
    "    for t in range(n2):\n",
    "        x_input=on_sample().float()\n",
    "        y=model(x_input)\n",
    "        regularization+=y**2   \n",
    "    regularization*=beta/n2\n",
    "    \n",
    "    loss+=regularization\n",
    "    \n",
    "    #and step the optimizer\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    #print the error\n",
    "    if((i+1)%print_every_iter==0):\n",
    "        in_error=0\n",
    "        on_error=0\n",
    "        \n",
    "        for t in range(n3):\n",
    "            in_x_test=in_sample()\n",
    "            in_error_instant=abs((model(in_x_test.float())-U_groundtruth(in_x_test.float())).item())\n",
    "            in_error=max(in_error,in_error_instant)\n",
    "            \n",
    "            on_x_test=on_sample()\n",
    "            on_error_instant=abs((model(on_x_test.float())-U_groundtruth(on_x_test.float())).item())\n",
    "            on_error=max(on_error,on_error_instant)\n",
    "            \n",
    "        in_error_iter.append(in_error)\n",
    "        on_error_iter.append(on_error)\n",
    "        \n",
    "        print(\"Loss at the\",i+1,\"th iteration:\", loss)\n",
    "        print(\"Error in Omega at the\",i+1,\"th iteration:\",in_error)\n",
    "        print(\"Error on the border of Omega at the\",i+1,\"th iteration:\",on_error)\n",
    "        \n",
    "print(\"Traning Completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in Omega at the 100 th iteration: 0.2502940595149994\n",
      "Error on the border of Omega at the 100 th iteration: 0.028751816600561142\n",
      "Error in Omega at the 200 th iteration: 0.25042784214019775\n",
      "Error on the border of Omega at the 200 th iteration: 0.02844119817018509\n",
      "Error in Omega at the 300 th iteration: 0.25063925981521606\n",
      "Error on the border of Omega at the 300 th iteration: 0.029561927542090416\n",
      "Error in Omega at the 400 th iteration: 0.25096067786216736\n",
      "Error on the border of Omega at the 400 th iteration: 0.029839906841516495\n",
      "Error in Omega at the 500 th iteration: 0.25031453371047974\n",
      "Error on the border of Omega at the 500 th iteration: 0.031862854957580566\n",
      "Error in Omega at the 600 th iteration: 0.2525257468223572\n",
      "Error on the border of Omega at the 600 th iteration: 0.033805232495069504\n",
      "Error in Omega at the 700 th iteration: 0.2545129656791687\n",
      "Error on the border of Omega at the 700 th iteration: 0.03701063245534897\n",
      "Error in Omega at the 800 th iteration: 0.2592138946056366\n",
      "Error on the border of Omega at the 800 th iteration: 0.04160378500819206\n",
      "Error in Omega at the 900 th iteration: 0.2717975080013275\n",
      "Error on the border of Omega at the 900 th iteration: 0.049876194447278976\n",
      "Error in Omega at the 1000 th iteration: 0.2951499819755554\n",
      "Error on the border of Omega at the 1000 th iteration: 0.055591337382793427\n",
      "Error in Omega at the 1100 th iteration: 0.3030652701854706\n",
      "Error on the border of Omega at the 1100 th iteration: 0.05683373659849167\n",
      "Error in Omega at the 1200 th iteration: 0.3049330711364746\n",
      "Error on the border of Omega at the 1200 th iteration: 0.05639678239822388\n",
      "Error in Omega at the 1300 th iteration: 0.30709338188171387\n",
      "Error on the border of Omega at the 1300 th iteration: 0.059185050427913666\n",
      "Error in Omega at the 1400 th iteration: 0.30906111001968384\n",
      "Error on the border of Omega at the 1400 th iteration: 0.058734774589538574\n",
      "Error in Omega at the 1500 th iteration: 0.311723917722702\n",
      "Error on the border of Omega at the 1500 th iteration: 0.06092968210577965\n",
      "Error in Omega at the 1600 th iteration: 0.3153327405452728\n",
      "Error on the border of Omega at the 1600 th iteration: 0.06336389482021332\n",
      "Error in Omega at the 1700 th iteration: 0.3191598057746887\n",
      "Error on the border of Omega at the 1700 th iteration: 0.06538835912942886\n",
      "Error in Omega at the 1800 th iteration: 0.32460519671440125\n",
      "Error on the border of Omega at the 1800 th iteration: 0.06972160935401917\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-90e3e10b0119>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mx_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mregularization\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mregularization\u001b[0m\u001b[1;33m*=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mn2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-cf9a8769b208>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear6\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m    992\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(iterations):\n",
    "    #calculate the loss \n",
    "    loss=torch.zeros(1)\n",
    "    for t in range(n1):\n",
    "        #if I miss out the \".float()\" there will be an error and I don't know why\n",
    "        #It seems to have something to do with the usage of relu()**3 in DeepRitzNet\n",
    "        x_input=in_sample()\n",
    "        y=model(x_input.float())\n",
    "        #there will be an error without \"retain_graph=True\" , I don't know why\n",
    "        y.backward(retain_graph=True)\n",
    "        loss+=0.5*((x_input.grad.float()[0])**2+(x_input.grad.float()[1])**2)-y      \n",
    "        if i > 4000:\n",
    "            print(x_input.grad.float())##for checking\n",
    "    loss/=n1\n",
    "    \n",
    "    regularization=torch.zeros(1)\n",
    "    for t in range(n2):\n",
    "        x_input=on_sample().float()\n",
    "        y=model(x_input)\n",
    "        regularization+=y**2   \n",
    "    regularization*=beta/n2\n",
    "    \n",
    "    loss+=regularization\n",
    "    \n",
    "    #and step the optimizer\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    #print the error\n",
    "    if((i+1)%print_every_iter==0):\n",
    "        in_error=0\n",
    "        on_error=0\n",
    "        \n",
    "        for t in range(n3):\n",
    "            in_x_test=in_sample()\n",
    "            in_error_instant=abs((model(in_x_test.float())-U_groundtruth(in_x_test.float())).item())\n",
    "            in_error=max(in_error,in_error_instant)\n",
    "            \n",
    "            on_x_test=on_sample()\n",
    "            on_error_instant=abs((model(on_x_test.float())-U_groundtruth(on_x_test.float())).item())\n",
    "            on_error=max(on_error,on_error_instant)\n",
    "            \n",
    "        in_error_iter.append(in_error)\n",
    "        on_error_iter.append(on_error)\n",
    "        \n",
    "        print(\"Error in Omega at the\",i+1,\"th iteration:\",in_error)\n",
    "        print(\"Error on the border of Omega at the\",i+1,\"th iteration:\",on_error)\n",
    "        \n",
    "print(\"Traning Completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "points=np.arange(-1,1,0.01)\n",
    "xs,ys=np.meshgrid(points,points)\n",
    "xs=torch.tensor(xs)\n",
    "ys=torch.tensor(ys)\n",
    "xl,yl=xs.size()\n",
    "z=np.zeros((xl,yl))\n",
    "\n",
    "for i in range(xl):\n",
    "    for j in range(yl):      \n",
    "        re=np.zeros(m)\n",
    "        re[0]=xs[i][j]\n",
    "        re[1]=ys[i][j]\n",
    "        re=torch.tensor(re)        \n",
    "        z[i][j]=model(re.float()).item()\n",
    "\n",
    "fig=plt.figure()\n",
    "ax=fig.add_subplot(111)\n",
    "ax.imshow(z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear1.weight',\n",
       "              tensor([[-0.2092,  0.1361,  0.0780,  0.1315,  0.1947,  0.0843,  0.1846,\n",
       "                        0.3104,  0.0926, -0.2206],\n",
       "                      [-0.2483, -0.0207, -0.1775,  0.1632, -0.2064, -0.3035,  0.2630,\n",
       "                        0.2025,  0.0429, -0.3153],\n",
       "                      [-0.0505,  0.2415,  0.2804, -0.2930,  0.1795,  0.1079, -0.2927,\n",
       "                       -0.3083,  0.0316,  0.2897],\n",
       "                      [-0.2224, -0.1822, -0.1389,  0.1490,  0.2506, -0.1238,  0.3138,\n",
       "                        0.0015, -0.1234,  0.1603],\n",
       "                      [ 0.0097,  0.3130, -0.0660,  0.3074, -0.2805, -0.1529,  0.0548,\n",
       "                        0.2316,  0.0149, -0.0860],\n",
       "                      [-0.1591, -0.2327,  0.2681, -0.3145,  0.2550, -0.1384,  0.0043,\n",
       "                        0.1971, -0.3040,  0.1625],\n",
       "                      [-0.2293, -0.1094, -0.0528, -0.0843,  0.1030,  0.1963, -0.1135,\n",
       "                       -0.0785, -0.1855,  0.1872],\n",
       "                      [-0.0925,  0.2533, -0.0185, -0.0051,  0.0968, -0.1638, -0.0587,\n",
       "                        0.1768,  0.1982, -0.0029],\n",
       "                      [-0.2472, -0.1731,  0.3088,  0.2290,  0.1422,  0.0072, -0.0865,\n",
       "                        0.1438, -0.2300, -0.0019],\n",
       "                      [ 0.2727, -0.2523,  0.2972, -0.0216,  0.1066, -0.0553, -0.1569,\n",
       "                       -0.2031,  0.2218, -0.2943]])),\n",
       "             ('linear1.bias',\n",
       "              tensor([ 0.1205, -0.2690, -0.1990,  0.0801, -0.2248, -0.0842, -0.2615,\n",
       "                      -0.1960,  0.0726,  0.1042])),\n",
       "             ('linear2.weight',\n",
       "              tensor([[ 0.2472, -0.2569, -0.1040,  0.0476, -0.0143, -0.1071,  0.1854,\n",
       "                       -0.1827, -0.0800,  0.1571],\n",
       "                      [-0.1620, -0.0818, -0.2501, -0.0787, -0.1445,  0.0368, -0.0091,\n",
       "                        0.1437,  0.0999, -0.0929],\n",
       "                      [ 0.0573,  0.1784,  0.1461,  0.1043, -0.1398, -0.0486, -0.2256,\n",
       "                       -0.1543,  0.1907,  0.2215],\n",
       "                      [-0.1452, -0.0450,  0.0404, -0.2289,  0.2591,  0.1484,  0.2451,\n",
       "                        0.0270, -0.2026,  0.1765],\n",
       "                      [-0.2931,  0.0970,  0.1615,  0.1767,  0.1934,  0.0751,  0.1261,\n",
       "                        0.2081,  0.2345, -0.3140],\n",
       "                      [-0.0559, -0.2975,  0.2119,  0.2667,  0.0356, -0.2374, -0.2256,\n",
       "                       -0.0744, -0.2973,  0.2812],\n",
       "                      [ 0.1939, -0.2597, -0.3114,  0.2406,  0.1543, -0.0380,  0.0807,\n",
       "                        0.0248,  0.1965,  0.1886],\n",
       "                      [-0.0413, -0.2994,  0.0003, -0.0107,  0.0164,  0.2893, -0.2379,\n",
       "                       -0.2838,  0.0572, -0.1437],\n",
       "                      [ 0.1058,  0.3075, -0.0050,  0.2112, -0.1214, -0.1146,  0.1496,\n",
       "                       -0.2172,  0.1375, -0.0629],\n",
       "                      [-0.0581, -0.1474, -0.0933, -0.2485, -0.0955,  0.0055, -0.0048,\n",
       "                       -0.0714,  0.0037, -0.3000]])),\n",
       "             ('linear2.bias',\n",
       "              tensor([ 0.0049,  0.3021, -0.0020, -0.1317, -0.2824,  0.1776,  0.2988,\n",
       "                       0.1056, -0.2214, -0.0696])),\n",
       "             ('linear3.weight',\n",
       "              tensor([[-0.0973,  0.1851, -0.1524,  0.3150,  0.1452, -0.0587,  0.1925,\n",
       "                       -0.2858,  0.2597, -0.2908],\n",
       "                      [-0.1871,  0.2526, -0.2414, -0.0182, -0.2968,  0.2179, -0.2266,\n",
       "                        0.2172, -0.2008, -0.1136],\n",
       "                      [-0.0312,  0.2817,  0.1165,  0.2783, -0.0936, -0.3140, -0.1893,\n",
       "                        0.1681,  0.0541,  0.0268],\n",
       "                      [ 0.1603,  0.0711, -0.3121, -0.0035, -0.1499, -0.0611,  0.0400,\n",
       "                        0.1743,  0.0304, -0.0360],\n",
       "                      [-0.1179, -0.2902, -0.2367,  0.2155,  0.0188,  0.2765, -0.0900,\n",
       "                        0.2922, -0.2261, -0.2316],\n",
       "                      [-0.1138, -0.2635,  0.1790,  0.2008, -0.0634, -0.3058, -0.0575,\n",
       "                        0.0045, -0.0575, -0.0309],\n",
       "                      [ 0.0032, -0.2154, -0.1528, -0.1629,  0.2823, -0.2308,  0.1014,\n",
       "                       -0.0792, -0.1760, -0.1342],\n",
       "                      [ 0.1713, -0.0072,  0.0083,  0.2164,  0.0592, -0.2816, -0.2847,\n",
       "                        0.0589, -0.0689,  0.2415],\n",
       "                      [ 0.2395,  0.1890, -0.0278, -0.0426, -0.0101, -0.0188, -0.2943,\n",
       "                        0.0473,  0.1926, -0.1697],\n",
       "                      [ 0.0072, -0.2363,  0.1195,  0.1555,  0.3065, -0.2731, -0.1448,\n",
       "                       -0.1836,  0.1808,  0.2794]])),\n",
       "             ('linear3.bias',\n",
       "              tensor([-0.0380,  0.2717, -0.0153,  0.2269, -0.1178, -0.0221,  0.1076,\n",
       "                       0.2600, -0.0245, -0.1260])),\n",
       "             ('linear4.weight',\n",
       "              tensor([[ 0.2960,  0.2436, -0.2434, -0.3110,  0.1109,  0.2783,  0.0535,\n",
       "                       -0.0318, -0.0718, -0.1244],\n",
       "                      [-0.0356,  0.1111, -0.0087,  0.0357,  0.2847,  0.2663,  0.1199,\n",
       "                       -0.1916, -0.0776, -0.0166],\n",
       "                      [-0.0192,  0.2497,  0.1619,  0.0747,  0.3137, -0.2215,  0.1712,\n",
       "                        0.0549,  0.0096, -0.1152],\n",
       "                      [ 0.1903, -0.0566,  0.0384,  0.0655, -0.2544,  0.2830, -0.2537,\n",
       "                       -0.1814,  0.2473,  0.2944],\n",
       "                      [-0.2613,  0.1959,  0.2376,  0.1030, -0.0853,  0.0042, -0.2290,\n",
       "                        0.0148,  0.2601, -0.2039],\n",
       "                      [-0.1769,  0.0511, -0.0764, -0.0462,  0.0449, -0.0927, -0.2060,\n",
       "                       -0.1728, -0.0179,  0.0073],\n",
       "                      [-0.0436,  0.0596, -0.0298,  0.1472,  0.2601,  0.0539,  0.2270,\n",
       "                       -0.1375, -0.3039, -0.1098],\n",
       "                      [-0.2499, -0.0229, -0.1164,  0.0418,  0.1421, -0.0398,  0.0777,\n",
       "                       -0.1134,  0.1501,  0.2893],\n",
       "                      [-0.0292,  0.0397, -0.1943, -0.3005, -0.3106, -0.2558, -0.0542,\n",
       "                       -0.2937,  0.1536,  0.0416],\n",
       "                      [-0.1748, -0.1495,  0.1326, -0.1056, -0.1325, -0.0449,  0.2440,\n",
       "                        0.1076,  0.2509, -0.1446]])),\n",
       "             ('linear4.bias',\n",
       "              tensor([-0.3024,  0.2309, -0.0170,  0.1335,  0.0470, -0.2724,  0.1541,\n",
       "                       0.0083,  0.1477, -0.0246])),\n",
       "             ('linear5.weight',\n",
       "              tensor([[-0.1502, -0.0068,  0.0762,  0.1768, -0.1743,  0.0920, -0.2739,\n",
       "                        0.2230,  0.3047,  0.1768],\n",
       "                      [ 0.2236,  0.1802,  0.1965,  0.3147, -0.0773,  0.0314, -0.0712,\n",
       "                       -0.2069,  0.2118,  0.1932],\n",
       "                      [ 0.1018, -0.0070, -0.2699,  0.2310,  0.2041, -0.3151,  0.1915,\n",
       "                        0.1685,  0.1769,  0.1886],\n",
       "                      [ 0.3104,  0.0548,  0.3092,  0.0211, -0.0591,  0.0399,  0.1919,\n",
       "                        0.1342, -0.2705, -0.2580],\n",
       "                      [-0.0184,  0.0671, -0.1260,  0.2315,  0.0918,  0.1344, -0.0206,\n",
       "                        0.2278,  0.3138, -0.2898],\n",
       "                      [-0.1985, -0.2986,  0.2160,  0.1812, -0.0445,  0.0468,  0.1278,\n",
       "                       -0.0563,  0.2444, -0.0786],\n",
       "                      [ 0.1998, -0.2903,  0.0836,  0.1362, -0.2483, -0.0206,  0.1912,\n",
       "                       -0.0811, -0.3118,  0.0378],\n",
       "                      [ 0.3025,  0.0138, -0.0921,  0.3058, -0.3029,  0.2917, -0.1114,\n",
       "                       -0.1508,  0.1449,  0.0718],\n",
       "                      [-0.3124, -0.2326, -0.2668, -0.1281, -0.0294,  0.2408, -0.2897,\n",
       "                        0.0396, -0.2309, -0.0925],\n",
       "                      [ 0.1649, -0.0063, -0.3156,  0.2772, -0.1849,  0.1651, -0.0777,\n",
       "                        0.0231,  0.2285,  0.3071]])),\n",
       "             ('linear5.bias',\n",
       "              tensor([ 0.1925, -0.1515, -0.1613, -0.1160,  0.0218,  0.1496,  0.0656,\n",
       "                      -0.1054,  0.2211, -0.1739])),\n",
       "             ('linear6.weight',\n",
       "              tensor([[-0.1469, -0.2651,  0.3019,  0.0972, -0.0333, -0.2609, -0.0185,\n",
       "                        0.0155, -0.3095, -0.1356],\n",
       "                      [ 0.0003,  0.0525, -0.1617, -0.1042,  0.1686, -0.0149,  0.2391,\n",
       "                        0.1846,  0.3150, -0.2323],\n",
       "                      [ 0.0285,  0.2428,  0.0869, -0.0667, -0.1641,  0.1261, -0.3124,\n",
       "                       -0.1884, -0.0383,  0.1162],\n",
       "                      [ 0.1355, -0.2845, -0.1032,  0.1212, -0.1618,  0.2448, -0.2908,\n",
       "                       -0.2029,  0.1591, -0.2666],\n",
       "                      [-0.0261, -0.2053, -0.0261, -0.0283,  0.1102, -0.2173, -0.3065,\n",
       "                       -0.0245, -0.2149,  0.1499],\n",
       "                      [-0.2114,  0.1580, -0.3010, -0.2757,  0.0277, -0.0811,  0.1645,\n",
       "                       -0.0167, -0.1181,  0.1246],\n",
       "                      [-0.1020, -0.1947,  0.0872,  0.1929,  0.2551,  0.0951,  0.2444,\n",
       "                       -0.1786, -0.0443,  0.2303],\n",
       "                      [ 0.1934, -0.1052,  0.2934, -0.2262, -0.2983, -0.1365, -0.3060,\n",
       "                       -0.1382,  0.0990, -0.2221],\n",
       "                      [-0.0934,  0.1506, -0.2185, -0.1087,  0.2949,  0.1129, -0.1415,\n",
       "                       -0.2719,  0.2891,  0.1965],\n",
       "                      [-0.0726,  0.0213, -0.2895, -0.0350, -0.2775,  0.0557, -0.1697,\n",
       "                        0.2912,  0.0312,  0.1664]])),\n",
       "             ('linear6.bias',\n",
       "              tensor([ 0.1887, -0.2738,  0.1869, -0.1315, -0.0357, -0.2231,  0.1197,\n",
       "                       0.1914,  0.0755,  0.2974])),\n",
       "             ('linear7.weight',\n",
       "              tensor([[ 0.1788,  0.1175,  0.2537, -0.2389,  0.2914, -0.0815,  0.0801,\n",
       "                        0.0498,  0.2286, -0.0760]])),\n",
       "             ('linear7.bias', tensor([-0.2329]))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  3,  12]) tensor([ 1,  8]) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([1,2],requires_grad=True)\n",
    "b=a**3\n",
    "c=b.sum()\n",
    "c.backward()\n",
    "print(a.grad,b,c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
