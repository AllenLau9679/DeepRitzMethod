{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-adaptive Sampling Method Test\n",
    "We will test the self-adaptive sampling method proposed by ourselves in following Possion equation case:\n",
    "$$\n",
    "\\begin{cases}\n",
    "    \\Delta u = 1\\qquad &u\\in\\Omega\\\\\n",
    "    u = 0\\qquad &u\\in\\partial\\Omega.\n",
    "\\end{cases}$$\n",
    "Here $\\Omega = \\{(x, y)|x^2+y^2 < 1\\}$\n",
    "\n",
    "The exact solution to this problem is $$u = \\frac{1}{4}(x^2+y^2-1).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from math import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "m = 10\n",
    "learning_rate = 0.01\n",
    "iterations = 400  #default 10000\n",
    "print_every_iter = 100\n",
    "beta = 500 #coefficient for the regularization term in the loss expression, is set to be 1000 in section 3.1\n",
    "n1 = 1000 #number of points in (0,1)^m\n",
    "n2 = 100  #number of points on the border of (0,1)^m\n",
    "n3 = 100  #number of points used for evaluating the error\n",
    "\n",
    "# Define our deep Ritz network model\n",
    "class DeepRitzNet(torch.nn.Module):\n",
    "    def __init__(self, m):\n",
    "        super(DeepRitzNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(m,m)\n",
    "        self.linear2 = torch.nn.Linear(m,m)\n",
    "        self.linear3 = torch.nn.Linear(m,m)\n",
    "        self.linear4 = torch.nn.Linear(m,m)\n",
    "        self.linear5 = torch.nn.Linear(m,m)\n",
    "        self.linear6 = torch.nn.Linear(m,m)\n",
    "        \n",
    "        self.linear7 = torch.nn.Linear(m,1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        y = y + F.relu(self.linear2(F.relu(self.linear1(y))))\n",
    "        y = y + F.relu(self.linear4(F.relu(self.linear3(y))))\n",
    "        y = y + F.relu(self.linear6(F.relu(self.linear5(y))))\n",
    "        output = F.relu(self.linear7(y))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Draw plots of approximate solutions\n",
    "def draw_graph(mod):\n",
    "    points = np.arange(-1, 1, 0.01)\n",
    "    xs, ys = np.meshgrid(points, points)\n",
    "    xs = torch.tensor(xs)\n",
    "    ys = torch.tensor(ys)\n",
    "    xl, yl = xs.size()\n",
    "    z = np.zeros((xl, yl))\n",
    "    for i in range(xl):\n",
    "        for j in range(yl):      \n",
    "            re = np.zeros(m)\n",
    "            re[0] = xs[i, j]\n",
    "            re[1] = ys[i, j]\n",
    "            re = torch.tensor(re)        \n",
    "            z[i, j] = mod(re.float()).item() + U_groundtruth(re)\n",
    "    \n",
    "    plt.imshow(z, cmap=cm.hot)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.savefig(\"loss_1.eps\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the relative loss\n",
    "def cal_loss(mod):\n",
    "    points = np.arange(-1, 1, 0.1)\n",
    "    xs, ys = np.meshgrid(points, points)\n",
    "    xs = torch.tensor(xs)\n",
    "    ys = torch.tensor(ys)\n",
    "    xl, yl = xs.size()\n",
    "    z = np.zeros((xl, yl))\n",
    "    mmm = 0\n",
    "    t = 0\n",
    "    for i in range(xl):\n",
    "        for j in range(yl):      \n",
    "            re = np.zeros(m)\n",
    "            re[0] = xs[i, j]\n",
    "            re[1] = ys[i, j]\n",
    "            re = torch.tensor(re)        \n",
    "            z[i, j] = mod(re.float()).item() + U_groundtruth(re)\n",
    "            if re[0] ** 2 + re[1] ** 2 < 1 : \n",
    "                mmm += abs(z[i, j])\n",
    "                t = t + 1\n",
    "    \n",
    "    return mmm / t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# U_groundtruth = 1/4*(x^2+y^2)-1/4\n",
    "# take in a (m,) tensor (x, y, ...)\n",
    "def U_groundtruth(t):\n",
    "    #re = 0\n",
    "    re = (t[0] ** 2 + t[1] ** 2 - 1).item() / 4\n",
    "    return re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gamma = 100\n",
    "model = DeepRitzNet(m)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "in_error_iter = [] #record the error in Omega every print_every_iter=100 times\n",
    "on_error_iter = [] #record the error on the border of Omega every print_every_iter=100 times\n",
    "\n",
    "mm = 1\n",
    "points = np.arange(-1, 1, 0.1)\n",
    "xs, ys = np.meshgrid(points, points)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "xl, yl = xs.size()\n",
    "                \n",
    "lr1 = 0.01\n",
    "lr2 = 0.005\n",
    "optimizer1 = torch.optim.Adam(model.parameters(), lr=lr1)\n",
    "optimizer2 = torch.optim.Adam(model.parameters(), lr=lr2)\n",
    "ccc = 1\n",
    "\n",
    "# Training\n",
    "for k in range(600):\n",
    "    loss = torch.zeros(1)\n",
    "    for i in range(xl):\n",
    "        for j in range(yl):        \n",
    "            x_input = np.zeros(m)\n",
    "            x_input[0] = xs[i, j]\n",
    "            x_input[1] = ys[i, j]\n",
    "            if x_input[0] ** 2 + x_input[1] ** 2 < 1:\n",
    "                x_input = torch.tensor(x_input).float()\n",
    "                y = model(x_input)\n",
    "                \n",
    "                x1 = torch.zeros(m)\n",
    "                x2 = torch.zeros(m)\n",
    "                x1[0] = 0.0001\n",
    "                x2[1] = 0.0001\n",
    "                x_input_1 = x_input.float() + x1\n",
    "                x_input_2 = x_input.float() + x2\n",
    "                x_input_3 = x_input.float() - x1\n",
    "                x_input_4 = x_input.float() - x2\n",
    "                x_input_grad_1 = (model(x_input_1) - y) / 0.0001\n",
    "                x_input_grad_2 = (model(x_input_2) - y) / 0.0001\n",
    "                x_input_2_grad_x = (model(x_input_1) + model(x_input_3) - 2 * y) / 0.0001**2\n",
    "                x_input_2_grad_y = (model(x_input_2) + model(x_input_4) - 2 * y) / 0.0001**2\n",
    "\n",
    "                loss += 0.5 * ((x_input_grad_1) ** 2 + (x_input_grad_2) ** 2) - y\n",
    "                \n",
    "    loss /= (xl * yl)\n",
    "    \n",
    "    regularization = torch.zeros(1)\n",
    "    \n",
    "    grid = np.linspace(0, 2*pi, 200)\n",
    "    n2 = 1\n",
    "    \n",
    "    # Self-adaptive sampling\n",
    "    for i in range(200):\n",
    "        if i < 199:\n",
    "            grid_i_1 = grid[i+1]\n",
    "        else:\n",
    "            grid_i_1 = grid[0]\n",
    "        th = (grid[i] + grid_i_1) / 2\n",
    "        x1 = np.zeros(m)\n",
    "        x1[0] = cos(th)\n",
    "        x1[1] = sin(th)\n",
    "        x1 = torch.tensor(x1).float()\n",
    "        yy = model(x1)\n",
    "        t = floor(abs(yy)*100)\n",
    "        for theta in np.linspace(grid[i], grid_i_1, t):\n",
    "            x_input = np.zeros(m)\n",
    "            x_input[0] = cos(theta)\n",
    "            x_input[1] = sin(theta)\n",
    "            x_input = torch.tensor(x_input).float()\n",
    "            y = model(x_input)\n",
    "            regularization += y**2 \n",
    "            n2 = n2 + 1\n",
    "    regularization *= mm / n2\n",
    "    \n",
    "    if mm < 500:\n",
    "        mm = mm * 1.01\n",
    "        \n",
    "    #print loss\n",
    "    print(k, \" epoch, loss: \", loss.data[0].numpy())\n",
    "    print(k, \" epoch, regularization loss: \", regularization.data[0].numpy())\n",
    "    print(k, \" loss to real solution: \", cal_loss(model))\n",
    "    \n",
    "    loss += regularization\n",
    "    \n",
    "    #and step the optimizer\n",
    "    optimizer1.zero_grad()\n",
    "    optimizer2.zero_grad()\n",
    "    loss.backward()\n",
    "    if k < 270:\n",
    "        optimizer1.step()\n",
    "    else:\n",
    "        optimizer2.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cal_loss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "draw_graph(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python pytorch\n",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
