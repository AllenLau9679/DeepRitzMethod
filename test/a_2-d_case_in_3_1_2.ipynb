{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on a simple case\n",
    "Consider the following Possion Equation\n",
    "$$\n",
    "\\begin{cases}\n",
    "    \\Delta u = 0\\qquad &u\\in\\Omega\\\\\n",
    "    u(r,\\theta) = \\sqrt{r}sin(\\frac{\\theta}{2})\\qquad &u\\in\\partial\\Omega.\n",
    "\\end{cases}$$\n",
    "Here $\\Omega = (-1,1)\\times(-1,1)\\backslash[0,1)\\times\\{0\\}$\n",
    "\n",
    "The exact solution to this problem is $$u = \\sqrt{r}sin(\\frac{\\theta}{2}).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from math import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "m = 10\n",
    "learning_rate = 0.01\n",
    "iterations = 400  #default 10000\n",
    "print_every_iter = 100\n",
    "beta = 5 #coefficient for the regularization term in the loss expression, is set to be 1000 in section 3.1\n",
    "n1 = 1000 #number of points in (0,1)^m\n",
    "n2 = 100  #number of points on the border of (0,1)^m\n",
    "n3 = 100  #number of points used for evaluating the error\n",
    "\n",
    "#用DeepRitzNet模拟论文中的 -u\n",
    "class DeepRitzNet(torch.nn.Module):\n",
    "    def __init__(self, m):\n",
    "        super(DeepRitzNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(m,m)\n",
    "        self.linear2 = torch.nn.Linear(m,m)\n",
    "        self.linear3 = torch.nn.Linear(m,m)\n",
    "        self.linear4 = torch.nn.Linear(m,m)\n",
    "        self.linear5 = torch.nn.Linear(m,m)\n",
    "        self.linear6 = torch.nn.Linear(m,m)\n",
    "        self.linear7 = torch.nn.Linear(m,m)\n",
    "        self.linear8 = torch.nn.Linear(m,m)\n",
    "        self.linear9 = torch.nn.Linear(m,m)\n",
    "        self.linear10 = torch.nn.Linear(m,m)\n",
    "        \n",
    "        self.linear11 = torch.nn.Linear(m,1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        y = y + F.relu(self.linear2(F.relu(self.linear1(y))))\n",
    "        y = y + F.relu(self.linear4(F.relu(self.linear3(y))))\n",
    "        y = y + F.relu(self.linear6(F.relu(self.linear5(y))))\n",
    "        y = y + F.relu(self.linear8(F.relu(self.linear7(y))))\n",
    "        y = y + F.relu(self.linear10(F.relu(self.linear9(y))))\n",
    "        output = F.relu(self.linear11(y))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_graph1(mod):\n",
    "    points = np.arange(-1, 1.1, 0.01)\n",
    "    xs, ys = np.meshgrid(points, points)\n",
    "    xs = torch.tensor(xs)\n",
    "    ys = torch.tensor(ys)\n",
    "    xl, yl = xs.size()\n",
    "    z = np.zeros((xl, yl))\n",
    "    for i in range(xl):\n",
    "        for j in range(yl):      \n",
    "            re = np.zeros(m)\n",
    "            re[0] = xs[i, j]\n",
    "            re[1] = ys[i, j]\n",
    "            re = torch.tensor(re)        \n",
    "            z[i, j] = mod(re.float()).item() \n",
    "            #z[i, j] =  U_groundtruth(re)\n",
    "    \n",
    "    plt.imshow(z, cmap=cm.hot)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    #plt.savefig(\"loss_1.eps\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_graph2():\n",
    "    points = np.arange(-1, 1.1, 0.01)\n",
    "    xs, ys = np.meshgrid(points, points)\n",
    "    xs = torch.tensor(xs)\n",
    "    ys = torch.tensor(ys)\n",
    "    xl, yl = xs.size()\n",
    "    z = np.zeros((xl, yl))\n",
    "    for i in range(xl):\n",
    "        for j in range(yl):      \n",
    "            re = np.zeros(m)\n",
    "            re[0] = xs[i, j]\n",
    "            re[1] = ys[i, j]\n",
    "            re = torch.tensor(re)        \n",
    "            z[i, j] = U_groundtruth(re)\n",
    "    \n",
    "    plt.imshow(z, cmap=cm.hot)\n",
    "    plt.colorbar() \n",
    "    #plt.savefig(\"loss_1.eps\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_graph(mod):\n",
    "    points = np.arange(-1, 1.1, 0.01)\n",
    "    xs, ys = np.meshgrid(points, points)\n",
    "    xs = torch.tensor(xs)\n",
    "    ys = torch.tensor(ys)\n",
    "    xl, yl = xs.size()\n",
    "    z = np.zeros((xl, yl))\n",
    "    for i in range(xl):\n",
    "        for j in range(yl):      \n",
    "            re = np.zeros(m)\n",
    "            re[0] = xs[i, j]\n",
    "            re[1] = ys[i, j]\n",
    "            re = torch.tensor(re)        \n",
    "            z[i, j] = mod(re.float()).item() - U_groundtruth(re)\n",
    "            #z[i, j] =  U_groundtruth(re)\n",
    "    \n",
    "    plt.imshow(z, cmap=cm.hot)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    #plt.savefig(\"loss_1.eps\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_loss(mod):\n",
    "    points = np.arange(-1, 1.1, 0.1)\n",
    "    xs, ys = np.meshgrid(points, points)\n",
    "    xs = torch.tensor(xs)\n",
    "    ys = torch.tensor(ys)\n",
    "    xl, yl = xs.size()\n",
    "    z = np.zeros((xl, yl))\n",
    "    mmm = 0\n",
    "    n = 0\n",
    "    for i in np.arange(1, xl):\n",
    "        for j in np.arange(1, yl):      \n",
    "            re = np.zeros(m)\n",
    "            re[0] = xs[i, j]\n",
    "            re[1] = ys[i, j]\n",
    "            #not on border\n",
    "            if (i<xl/2 or j != yl/2+1):\n",
    "                re = torch.tensor(re)        \n",
    "                z[i, j] = (mod(re.float()).item() - U_groundtruth(re))#/ U_groundtruth(re)           \n",
    "                if abs(z[i, j]) > mmm:\n",
    "                    mmm += abs(z[i, j])\n",
    "                n += 1\n",
    "    \n",
    "    return mmm /n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#U_groundtruth (r, theta) = sqrt(r) * sin(theta/2)\n",
    "#take in a (m,) tensor (x, y, ...)\n",
    "def U_groundtruth(t):\n",
    "    theta = atan2(t[1].item(), t[0].item()) + 2*pi #-pi < atan(·) < pi\n",
    "    return sqrt(sqrt((t[0] ** 2 + t[1] ** 2).item())) * sin(theta/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#相对误差\n",
    "#余冰的例子里面是\n",
    "#print(np.linalg.norm(np.reshape(u_solve[:,0]-pu,[-1]),ord=2)/np.linalg.norm(np.reshape(pu,[-1]),ord=2))\n",
    "def relative_err(mod):    \n",
    "    points = np.arange(-1, 1.1, 0.1)\n",
    "    xs, ys = np.meshgrid(points, points)\n",
    "    xs = torch.tensor(xs)\n",
    "    ys = torch.tensor(ys)\n",
    "    xl, yl = xs.size()\n",
    "    z = np.zeros((xl, yl))\n",
    "    w = np.zeros((xl, yl))\n",
    "    n = 0\n",
    "    for i in np.arange(1, xl):\n",
    "        for j in np.arange(1, yl):      \n",
    "            re = np.zeros(m)\n",
    "            re[0] = xs[i, j]\n",
    "            re[1] = ys[i, j]\n",
    "            #not on border\n",
    "            if (i<xl/2 or j != yl/2+1):\n",
    "                re = torch.tensor(re)        \n",
    "                z[i, j] = (mod(re.float()).item() - U_groundtruth(re))#/ U_groundtruth(re)           \n",
    "                w[i, j] = U_groundtruth(re)\n",
    "                n += 1\n",
    "    z = z ** 2\n",
    "    w = w ** 2\n",
    "    return np.sum(z) / np.sum(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = DeepRitzNet(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  epoch, loss:  7.1988065e-06\n",
      "0  epoch, regularization loss:  37.236332\n",
      "0  loss to real solution:  0.004979210743492154\n",
      "1  epoch, loss:  1.635388e-05\n",
      "1  epoch, regularization loss:  37.90547\n",
      "1  loss to real solution:  0.004989483902042416\n",
      "2  epoch, loss:  5.851051e-06\n",
      "2  epoch, regularization loss:  38.05938\n",
      "2  loss to real solution:  0.004983258941953686\n",
      "3  epoch, loss:  7.074004e-06\n",
      "3  epoch, regularization loss:  38.21535\n",
      "3  loss to real solution:  0.004977094033544568\n",
      "4  epoch, loss:  1.0460918e-05\n",
      "4  epoch, regularization loss:  38.479958\n",
      "4  loss to real solution:  0.004975070753877667\n",
      "5  epoch, loss:  8.1220505e-06\n",
      "5  epoch, regularization loss:  38.843914\n",
      "5  loss to real solution:  0.004976585605924633\n",
      "6  epoch, loss:  4.968795e-06\n",
      "6  epoch, regularization loss:  39.275566\n",
      "6  loss to real solution:  0.004979747930353192\n",
      "7  epoch, loss:  4.6258197e-06\n",
      "7  epoch, regularization loss:  39.72231\n",
      "7  loss to real solution:  0.004982938268964794\n",
      "8  epoch, loss:  6.601671e-06\n",
      "8  epoch, regularization loss:  40.139362\n",
      "8  loss to real solution:  0.004984903285091427\n",
      "9  epoch, loss:  6.8262184e-06\n",
      "9  epoch, regularization loss:  40.50168\n",
      "9  loss to real solution:  0.004985142299716977\n",
      "10  epoch, loss:  5.1937945e-06\n",
      "10  epoch, regularization loss:  40.823803\n",
      "10  loss to real solution:  0.004983932176416424\n",
      "11  epoch, loss:  3.7963991e-06\n",
      "11  epoch, regularization loss:  41.12817\n",
      "11  loss to real solution:  0.004981990406101254\n",
      "12  epoch, loss:  4.128897e-06\n",
      "12  epoch, regularization loss:  41.43795\n",
      "12  loss to real solution:  0.004979955503528622\n",
      "13  epoch, loss:  5.06171e-06\n",
      "13  epoch, regularization loss:  41.779987\n",
      "13  loss to real solution:  0.004978553453271892\n",
      "14  epoch, loss:  5.3254253e-06\n",
      "14  epoch, regularization loss:  42.163185\n",
      "14  loss to real solution:  0.004978216687028912\n",
      "15  epoch, loss:  4.1726216e-06\n",
      "15  epoch, regularization loss:  42.583588\n",
      "15  loss to real solution:  0.004978979924505261\n",
      "16  epoch, loss:  3.3104072e-06\n",
      "16  epoch, regularization loss:  43.026657\n",
      "16  loss to real solution:  0.004980427423303631\n",
      "17  epoch, loss:  3.1860613e-06\n",
      "17  epoch, regularization loss:  43.480854\n",
      "17  loss to real solution:  0.004981990555112866\n",
      "18  epoch, loss:  4.1840035e-06\n",
      "18  epoch, regularization loss:  43.92787\n",
      "18  loss to real solution:  0.004983157316034344\n",
      "19  epoch, loss:  4.192203e-06\n",
      "19  epoch, regularization loss:  44.346542\n",
      "19  loss to real solution:  0.004983435669725445\n",
      "20  epoch, loss:  3.7367295e-06\n",
      "20  epoch, regularization loss:  44.742107\n",
      "20  loss to real solution:  0.004982855865543393\n",
      "21  epoch, loss:  3.2015485e-06\n",
      "21  epoch, regularization loss:  45.119614\n",
      "21  loss to real solution:  0.0049816344173603325\n",
      "22  epoch, loss:  3.3149615e-06\n",
      "22  epoch, regularization loss:  45.493744\n",
      "22  loss to real solution:  0.004980354258602169\n",
      "23  epoch, loss:  3.6037347e-06\n",
      "23  epoch, regularization loss:  45.874023\n",
      "23  loss to real solution:  0.004979580441301373\n",
      "24  epoch, loss:  4.2969677e-06\n",
      "24  epoch, regularization loss:  46.28319\n",
      "24  loss to real solution:  0.004979522624795941\n",
      "25  epoch, loss:  4.383507e-06\n",
      "25  epoch, regularization loss:  46.725784\n",
      "25  loss to real solution:  0.004980048933809308\n",
      "26  epoch, loss:  4.216349e-06\n",
      "26  epoch, regularization loss:  47.198135\n",
      "26  loss to real solution:  0.004980980554407146\n",
      "27  epoch, loss:  4.071507e-06\n",
      "27  epoch, regularization loss:  47.69572\n",
      "27  loss to real solution:  0.004982115873878506\n",
      "28  epoch, loss:  4.4572957e-06\n",
      "28  epoch, regularization loss:  48.204216\n",
      "28  loss to real solution:  0.0049830479415111815\n",
      "29  epoch, loss:  4.7273893e-06\n",
      "29  epoch, regularization loss:  48.710987\n",
      "29  loss to real solution:  0.004983670661037472\n",
      "30  epoch, loss:  4.746065e-06\n",
      "30  epoch, regularization loss:  49.20809\n",
      "30  loss to real solution:  0.0049839271100216185\n",
      "31  epoch, loss:  4.5151382e-06\n",
      "31  epoch, regularization loss:  49.69336\n",
      "31  loss to real solution:  0.004983627596681622\n",
      "32  epoch, loss:  4.373945e-06\n",
      "32  epoch, regularization loss:  50.178513\n",
      "32  loss to real solution:  0.004982998916690853\n",
      "33  epoch, loss:  4.0847162e-06\n",
      "33  epoch, regularization loss:  50.671276\n",
      "33  loss to real solution:  0.004982180544918087\n",
      "34  epoch, loss:  4.0737823e-06\n",
      "34  epoch, regularization loss:  51.189323\n",
      "34  loss to real solution:  0.004981756606882122\n",
      "35  epoch, loss:  3.7786342e-06\n",
      "35  epoch, regularization loss:  51.730354\n",
      "35  loss to real solution:  0.004981818148677853\n",
      "36  epoch, loss:  3.5158266e-06\n",
      "36  epoch, regularization loss:  52.29507\n",
      "36  loss to real solution:  0.004982214817588833\n",
      "37  epoch, loss:  3.3992237e-06\n",
      "37  epoch, regularization loss:  52.877525\n",
      "37  loss to real solution:  0.004982806095665005\n",
      "38  epoch, loss:  3.3737178e-06\n",
      "38  epoch, regularization loss:  53.467148\n",
      "38  loss to real solution:  0.0049833292754345206\n",
      "39  epoch, loss:  3.3491212e-06\n",
      "39  epoch, regularization loss:  54.05364\n",
      "39  loss to real solution:  0.004983643540924099\n",
      "40  epoch, loss:  3.1874285e-06\n",
      "40  epoch, regularization loss:  54.62819\n",
      "40  loss to real solution:  0.004983669170921353\n",
      "41  epoch, loss:  3.1232046e-06\n",
      "41  epoch, regularization loss:  55.187943\n",
      "41  loss to real solution:  0.004983298877065685\n",
      "42  epoch, loss:  2.8631282e-06\n",
      "42  epoch, regularization loss:  55.73946\n",
      "42  loss to real solution:  0.004982634434288052\n",
      "43  epoch, loss:  2.6153502e-06\n",
      "43  epoch, regularization loss:  56.291332\n",
      "43  loss to real solution:  0.004981812933271435\n",
      "44  epoch, loss:  2.6727405e-06\n",
      "44  epoch, regularization loss:  56.853172\n",
      "44  loss to real solution:  0.004981058338468579\n",
      "45  epoch, loss:  2.541107e-06\n",
      "45  epoch, regularization loss:  57.43345\n",
      "45  loss to real solution:  0.0049805980415993005\n",
      "46  epoch, loss:  2.5734469e-06\n",
      "46  epoch, regularization loss:  58.03624\n",
      "46  loss to real solution:  0.004980687597578076\n",
      "47  epoch, loss:  2.350263e-06\n",
      "47  epoch, regularization loss:  58.652054\n",
      "47  loss to real solution:  0.004981078008001355\n",
      "48  epoch, loss:  2.2974284e-06\n",
      "48  epoch, regularization loss:  59.27506\n",
      "48  loss to real solution:  0.0049814757199936185\n",
      "49  epoch, loss:  2.2509703e-06\n",
      "49  epoch, regularization loss:  59.89784\n",
      "49  loss to real solution:  0.004981629499977139\n",
      "50  epoch, loss:  2.220909e-06\n",
      "50  epoch, regularization loss:  60.51587\n",
      "50  loss to real solution:  0.004981544712369946\n",
      "51  epoch, loss:  2.170351e-06\n",
      "51  epoch, regularization loss:  61.12938\n",
      "51  loss to real solution:  0.004981229552810696\n",
      "52  epoch, loss:  2.0296097e-06\n",
      "52  epoch, regularization loss:  61.74409\n",
      "52  loss to real solution:  0.0049807598682098655\n",
      "53  epoch, loss:  1.9931713e-06\n",
      "53  epoch, regularization loss:  62.364574\n",
      "53  loss to real solution:  0.004980349639242199\n",
      "54  epoch, loss:  1.9298604e-06\n",
      "54  epoch, regularization loss:  62.994297\n",
      "54  loss to real solution:  0.004980110177581814\n",
      "55  epoch, loss:  2.002736e-06\n",
      "55  epoch, regularization loss:  63.638504\n",
      "55  loss to real solution:  0.004980122098510769\n",
      "56  epoch, loss:  1.8820355e-06\n",
      "56  epoch, regularization loss:  64.2968\n",
      "56  loss to real solution:  0.004980326095407513\n",
      "57  epoch, loss:  1.7681666e-06\n",
      "57  epoch, regularization loss:  64.96562\n",
      "57  loss to real solution:  0.004980629483049419\n",
      "58  epoch, loss:  1.86336e-06\n",
      "58  epoch, regularization loss:  65.63336\n",
      "58  loss to real solution:  0.0049808385463409694\n",
      "59  epoch, loss:  1.7654327e-06\n",
      "59  epoch, regularization loss:  66.29226\n",
      "59  loss to real solution:  0.00498093927819064\n",
      "60  epoch, loss:  1.8875008e-06\n",
      "60  epoch, regularization loss:  66.97697\n",
      "60  loss to real solution:  0.004980795034950284\n",
      "61  epoch, loss:  1.7786411e-06\n",
      "61  epoch, regularization loss:  67.65452\n",
      "61  loss to real solution:  0.004980537244861629\n",
      "62  epoch, loss:  1.6839026e-06\n",
      "62  epoch, regularization loss:  68.32702\n",
      "62  loss to real solution:  0.004980228492801693\n",
      "63  epoch, loss:  1.792306e-06\n",
      "63  epoch, regularization loss:  69.00631\n",
      "63  loss to real solution:  0.004980030158346203\n",
      "64  epoch, loss:  1.745392e-06\n",
      "64  epoch, regularization loss:  69.700554\n",
      "64  loss to real solution:  0.004979970851724652\n",
      "65  epoch, loss:  1.6515637e-06\n",
      "65  epoch, regularization loss:  70.41007\n",
      "65  loss to real solution:  0.0049800805242710385\n",
      "66  epoch, loss:  1.627878e-06\n",
      "66  epoch, regularization loss:  71.131134\n",
      "66  loss to real solution:  0.004980282882040051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67  epoch, loss:  1.6570286e-06\n",
      "67  epoch, regularization loss:  71.853966\n",
      "67  loss to real solution:  0.0049805299432926445\n",
      "68  epoch, loss:  1.6419981e-06\n",
      "68  epoch, regularization loss:  72.56839\n",
      "68  loss to real solution:  0.004980709204261807\n",
      "69  epoch, loss:  1.5773206e-06\n",
      "69  epoch, regularization loss:  73.27429\n",
      "69  loss to real solution:  0.004980651983802822\n",
      "70  epoch, loss:  1.6105705e-06\n",
      "70  epoch, regularization loss:  73.977356\n",
      "70  loss to real solution:  0.004980518767421749\n",
      "71  epoch, loss:  1.5554563e-06\n",
      "71  epoch, regularization loss:  74.68834\n",
      "71  loss to real solution:  0.004980289885585812\n",
      "72  epoch, loss:  1.6397208e-06\n",
      "72  epoch, regularization loss:  75.41344\n",
      "72  loss to real solution:  0.004980132231300381\n",
      "73  epoch, loss:  1.5190182e-06\n",
      "73  epoch, regularization loss:  76.15059\n",
      "73  loss to real solution:  0.004980160543506649\n",
      "74  epoch, loss:  1.552724e-06\n",
      "74  epoch, regularization loss:  76.89699\n",
      "74  loss to real solution:  0.004980352321451214\n",
      "75  epoch, loss:  1.6483748e-06\n",
      "75  epoch, regularization loss:  77.64579\n",
      "75  loss to real solution:  0.004980622479503659\n",
      "76  epoch, loss:  1.5463468e-06\n",
      "76  epoch, regularization loss:  78.39387\n",
      "76  loss to real solution:  0.004980849722211865\n",
      "77  epoch, loss:  1.5222063e-06\n",
      "77  epoch, regularization loss:  79.13618\n",
      "77  loss to real solution:  0.004980809340065029\n",
      "78  epoch, loss:  1.5536355e-06\n",
      "78  epoch, regularization loss:  79.88393\n",
      "78  loss to real solution:  0.004980640062873867\n",
      "79  epoch, loss:  1.5322271e-06\n",
      "79  epoch, regularization loss:  80.63812\n",
      "79  loss to real solution:  0.0049803666265659605\n",
      "80  epoch, loss:  1.4301993e-06\n",
      "80  epoch, regularization loss:  81.4033\n",
      "80  loss to real solution:  0.0049802378805332455\n",
      "81  epoch, loss:  1.4133474e-06\n",
      "81  epoch, regularization loss:  82.18441\n",
      "81  loss to real solution:  0.004980381378715542\n",
      "82  epoch, loss:  1.5140089e-06\n",
      "82  epoch, regularization loss:  82.97616\n",
      "82  loss to real solution:  0.004980708012168911\n",
      "83  epoch, loss:  1.4279225e-06\n",
      "83  epoch, regularization loss:  83.77808\n",
      "83  loss to real solution:  0.00498096922952464\n",
      "84  epoch, loss:  1.437943e-06\n",
      "84  epoch, regularization loss:  84.57992\n",
      "84  loss to real solution:  0.004981049695795086\n",
      "85  epoch, loss:  1.3650665e-06\n",
      "85  epoch, regularization loss:  85.38279\n",
      "85  loss to real solution:  0.0049810172112636835\n",
      "86  epoch, loss:  1.3217959e-06\n",
      "86  epoch, regularization loss:  86.189964\n",
      "86  loss to real solution:  0.004980933317726162\n",
      "87  epoch, loss:  1.3113201e-06\n",
      "87  epoch, regularization loss:  87.00441\n",
      "87  loss to real solution:  0.004980910518949536\n",
      "88  epoch, loss:  1.3591451e-06\n",
      "88  epoch, regularization loss:  87.82115\n",
      "88  loss to real solution:  0.00498091618139079\n",
      "89  epoch, loss:  1.2985657e-06\n",
      "89  epoch, regularization loss:  88.65331\n",
      "89  loss to real solution:  0.004980913052146939\n",
      "90  epoch, loss:  1.3577783e-06\n",
      "90  epoch, regularization loss:  89.496315\n",
      "90  loss to real solution:  0.004980891445463207\n",
      "91  epoch, loss:  1.4538857e-06\n",
      "91  epoch, regularization loss:  90.3444\n",
      "91  loss to real solution:  0.004980734536235837\n",
      "92  epoch, loss:  1.3550454e-06\n",
      "92  epoch, regularization loss:  91.200455\n",
      "92  loss to real solution:  0.004980657348220852\n",
      "93  epoch, loss:  1.3632452e-06\n",
      "93  epoch, regularization loss:  92.06161\n",
      "93  loss to real solution:  0.004980736920421627\n",
      "94  epoch, loss:  1.328172e-06\n",
      "94  epoch, regularization loss:  92.93367\n",
      "94  loss to real solution:  0.0049809897931270865\n",
      "95  epoch, loss:  1.3227061e-06\n",
      "95  epoch, regularization loss:  93.81606\n",
      "95  loss to real solution:  0.004981168607061413\n",
      "96  epoch, loss:  1.2780694e-06\n",
      "96  epoch, regularization loss:  94.70608\n",
      "96  loss to real solution:  0.0049811063202076225\n",
      "97  epoch, loss:  1.3518573e-06\n",
      "97  epoch, regularization loss:  95.60237\n",
      "97  loss to real solution:  0.004980849275177029\n",
      "98  epoch, loss:  1.2789806e-06\n",
      "98  epoch, regularization loss:  96.506996\n",
      "98  loss to real solution:  0.0049806010218315395\n",
      "99  epoch, loss:  1.3236182e-06\n",
      "99  epoch, regularization loss:  97.42425\n",
      "99  loss to real solution:  0.0049806661399059565\n",
      "100  epoch, loss:  1.2375322e-06\n",
      "100  epoch, regularization loss:  98.34346\n",
      "100  loss to real solution:  0.004980860600059536\n",
      "101  epoch, loss:  1.3254391e-06\n",
      "101  epoch, regularization loss:  99.46126\n",
      "101  loss to real solution:  0.004980363050287273\n",
      "102  epoch, loss:  1.3910292e-06\n",
      "102  epoch, regularization loss:  100.606705\n",
      "102  loss to real solution:  0.004980055490320233\n",
      "103  epoch, loss:  1.3878401e-06\n",
      "103  epoch, regularization loss:  101.78304\n",
      "103  loss to real solution:  0.004979966530387905\n",
      "104  epoch, loss:  1.2475529e-06\n",
      "104  epoch, regularization loss:  102.98097\n",
      "104  loss to real solution:  0.004980013618057278\n",
      "105  epoch, loss:  1.4361215e-06\n",
      "105  epoch, regularization loss:  104.17587\n",
      "105  loss to real solution:  0.00498009602147868\n",
      "106  epoch, loss:  1.436577e-06\n",
      "106  epoch, regularization loss:  105.34099\n",
      "106  loss to real solution:  0.004980194816177395\n",
      "107  epoch, loss:  1.4711935e-06\n",
      "107  epoch, regularization loss:  106.46698\n",
      "107  loss to real solution:  0.004980182746236828\n",
      "108  epoch, loss:  1.3687106e-06\n",
      "108  epoch, regularization loss:  107.55963\n",
      "108  loss to real solution:  0.004979960569923428\n",
      "109  epoch, loss:  1.3778197e-06\n",
      "109  epoch, regularization loss:  108.64794\n",
      "109  loss to real solution:  0.004979642281120327\n",
      "110  epoch, loss:  1.4256453e-06\n",
      "110  epoch, regularization loss:  109.770966\n",
      "110  loss to real solution:  0.004979393580740002\n",
      "111  epoch, loss:  1.4443202e-06\n",
      "111  epoch, regularization loss:  110.92717\n",
      "111  loss to real solution:  0.004979395219867734\n",
      "112  epoch, loss:  1.3290834e-06\n",
      "112  epoch, regularization loss:  112.1042\n",
      "112  loss to real solution:  0.004979605624263791\n",
      "113  epoch, loss:  1.4424986e-06\n",
      "113  epoch, regularization loss:  113.27245\n",
      "113  loss to real solution:  0.004979914227312115\n",
      "114  epoch, loss:  1.3632443e-06\n",
      "114  epoch, regularization loss:  114.41912\n",
      "114  loss to real solution:  0.004980123141592053\n",
      "115  epoch, loss:  1.3263505e-06\n",
      "115  epoch, regularization loss:  115.54153\n",
      "115  loss to real solution:  0.004980149516647366\n",
      "116  epoch, loss:  1.3222509e-06\n",
      "116  epoch, regularization loss:  116.64909\n",
      "116  loss to real solution:  0.004979962805097607\n",
      "117  epoch, loss:  1.352768e-06\n",
      "117  epoch, regularization loss:  117.763115\n",
      "117  loss to real solution:  0.004979721108263043\n",
      "118  epoch, loss:  1.411981e-06\n",
      "118  epoch, regularization loss:  118.91169\n",
      "118  loss to real solution:  0.0049796188862972525\n",
      "119  epoch, loss:  1.3655216e-06\n",
      "119  epoch, regularization loss:  120.08306\n",
      "119  loss to real solution:  0.00497968787867358\n",
      "120  epoch, loss:  1.3404705e-06\n",
      "120  epoch, regularization loss:  121.26735\n",
      "120  loss to real solution:  0.004979981729572323\n",
      "121  epoch, loss:  1.2926444e-06\n",
      "121  epoch, regularization loss:  122.44556\n",
      "121  loss to real solution:  0.004980185577457455\n",
      "122  epoch, loss:  1.2908228e-06\n",
      "122  epoch, regularization loss:  123.61361\n",
      "122  loss to real solution:  0.004980259934251812\n",
      "123  epoch, loss:  1.3532236e-06\n",
      "123  epoch, regularization loss:  124.78312\n",
      "123  loss to real solution:  0.004980217763965633\n",
      "124  epoch, loss:  1.2967441e-06\n",
      "124  epoch, regularization loss:  125.96569\n",
      "124  loss to real solution:  0.004980093935316112\n",
      "125  epoch, loss:  1.318152e-06\n",
      "125  epoch, regularization loss:  127.1581\n",
      "125  loss to real solution:  0.004980034926717785\n",
      "126  epoch, loss:  1.3422915e-06\n",
      "126  epoch, regularization loss:  128.37642\n",
      "126  loss to real solution:  0.004980142364089992\n",
      "127  epoch, loss:  1.2698708e-06\n",
      "127  epoch, regularization loss:  129.61562\n",
      "127  loss to real solution:  0.004980394044702557\n",
      "128  epoch, loss:  1.2571176e-06\n",
      "128  epoch, regularization loss:  130.86423\n",
      "128  loss to real solution:  0.0049806750806026725\n",
      "129  epoch, loss:  1.3591447e-06\n",
      "129  epoch, regularization loss:  132.1216\n",
      "129  loss to real solution:  0.004980794587915447\n",
      "130  epoch, loss:  1.3186078e-06\n",
      "130  epoch, regularization loss:  133.37822\n",
      "130  loss to real solution:  0.004980670312231091\n",
      "131  epoch, loss:  1.3254396e-06\n",
      "131  epoch, regularization loss:  134.62625\n",
      "131  loss to real solution:  0.004980465123241452\n",
      "132  epoch, loss:  1.3509463e-06\n",
      "132  epoch, regularization loss:  135.88087\n",
      "132  loss to real solution:  0.00498036737162402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133  epoch, loss:  1.3555003e-06\n",
      "133  epoch, regularization loss:  137.15344\n",
      "133  loss to real solution:  0.0049804119260959895\n",
      "134  epoch, loss:  1.3067657e-06\n",
      "134  epoch, regularization loss:  138.45723\n",
      "134  loss to real solution:  0.004980554232185391\n",
      "135  epoch, loss:  1.2102033e-06\n",
      "135  epoch, regularization loss:  139.80168\n",
      "135  loss to real solution:  0.004980757335012463\n",
      "136  epoch, loss:  1.3263505e-06\n",
      "136  epoch, regularization loss:  141.16743\n",
      "136  loss to real solution:  0.004980922886913326\n",
      "137  epoch, loss:  1.2931007e-06\n",
      "137  epoch, regularization loss:  142.52118\n",
      "137  loss to real solution:  0.004980959841793088\n",
      "138  epoch, loss:  1.2730592e-06\n",
      "138  epoch, regularization loss:  143.86945\n",
      "138  loss to real solution:  0.004980848381107357\n",
      "139  epoch, loss:  1.2111143e-06\n",
      "139  epoch, regularization loss:  145.22142\n",
      "139  loss to real solution:  0.004980629334037808\n",
      "140  epoch, loss:  1.2170349e-06\n",
      "140  epoch, regularization loss:  146.6064\n",
      "140  loss to real solution:  0.004980437705104855\n",
      "141  epoch, loss:  1.1450696e-06\n",
      "141  epoch, regularization loss:  148.04266\n",
      "141  loss to real solution:  0.004980527112072018\n",
      "142  epoch, loss:  1.2152133e-06\n",
      "142  epoch, regularization loss:  149.51279\n",
      "142  loss to real solution:  0.004980760911291149\n",
      "143  epoch, loss:  1.2029149e-06\n",
      "143  epoch, regularization loss:  150.96964\n",
      "143  loss to real solution:  0.0049808947237186705\n",
      "144  epoch, loss:  1.2129352e-06\n",
      "144  epoch, regularization loss:  152.42128\n",
      "144  loss to real solution:  0.004980814108436611\n",
      "145  epoch, loss:  1.1833296e-06\n",
      "145  epoch, regularization loss:  153.89305\n",
      "145  loss to real solution:  0.004980740347688702\n",
      "146  epoch, loss:  1.1846965e-06\n",
      "146  epoch, regularization loss:  155.38863\n",
      "146  loss to real solution:  0.004980729916875867\n",
      "147  epoch, loss:  1.1537243e-06\n",
      "147  epoch, regularization loss:  156.90718\n",
      "147  loss to real solution:  0.004980713823621777\n",
      "148  epoch, loss:  1.0808482e-06\n",
      "148  epoch, regularization loss:  158.43596\n",
      "148  loss to real solution:  0.004980813661401776\n",
      "149  epoch, loss:  1.0608069e-06\n",
      "149  epoch, regularization loss:  159.97575\n",
      "149  loss to real solution:  0.00498081932384303\n",
      "150  epoch, loss:  1.1036224e-06\n",
      "150  epoch, regularization loss:  161.5234\n",
      "150  loss to real solution:  0.004980686554496792\n",
      "151  epoch, loss:  1.0926907e-06\n",
      "151  epoch, regularization loss:  163.09021\n",
      "151  loss to real solution:  0.004980567643230465\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-d3e38a7258c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_increase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-53-2b41149f03fa>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(mod, learning_rate, beta, beta_increase, iterations, add_gamma, gamma, gamma_increase)\u001b[0m\n\u001b[0;32m     31\u001b[0m                     \u001b[0mx_input_grad_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_input_2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                     \u001b[0mx_input_2_grad_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_input_1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_input_3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                     \u001b[0mx_input_2_grad_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_input_2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_input_4\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_input_grad_1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_input_grad_2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-ea063ef8d8b7>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear6\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear8\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear7\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m    994\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 996\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    997\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, learning_rate=0.001, beta=50, beta_increase=1.01, iterations=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  epoch, loss:  0.24080813\n",
      "0  epoch, regularization loss:  7.472088\n",
      "0  loss to real solution:  0.014580638001853918\n",
      "1  epoch, loss:  0.22440334\n",
      "1  epoch, regularization loss:  7.5816307\n",
      "1  loss to real solution:  0.014276699315006232\n",
      "2  epoch, loss:  0.20911102\n",
      "2  epoch, regularization loss:  7.6856513\n",
      "2  loss to real solution:  0.013963661383087134\n",
      "3  epoch, loss:  0.19415504\n",
      "3  epoch, regularization loss:  7.7909102\n",
      "3  loss to real solution:  0.013653952966625188\n",
      "4  epoch, loss:  0.18013532\n",
      "4  epoch, regularization loss:  7.9060073\n",
      "4  loss to real solution:  0.013352498005325293\n",
      "5  epoch, loss:  0.1676016\n",
      "5  epoch, regularization loss:  8.025424\n",
      "5  loss to real solution:  0.012894802149835951\n",
      "6  epoch, loss:  0.15539083\n",
      "6  epoch, regularization loss:  8.150001\n",
      "6  loss to real solution:  0.012612094935480482\n",
      "7  epoch, loss:  0.1437958\n",
      "7  epoch, regularization loss:  8.281304\n",
      "7  loss to real solution:  0.012338446137014753\n",
      "8  epoch, loss:  0.13368683\n",
      "8  epoch, regularization loss:  8.419395\n",
      "8  loss to real solution:  0.012025994901544806\n",
      "9  epoch, loss:  0.123902544\n",
      "9  epoch, regularization loss:  8.564382\n",
      "9  loss to real solution:  0.01176662588585114\n",
      "10  epoch, loss:  0.11592698\n",
      "10  epoch, regularization loss:  8.717446\n",
      "10  loss to real solution:  0.01151677990425324\n",
      "11  epoch, loss:  0.10799545\n",
      "11  epoch, regularization loss:  8.880539\n",
      "11  loss to real solution:  0.01127372080553269\n",
      "12  epoch, loss:  0.10076102\n",
      "12  epoch, regularization loss:  9.0549345\n",
      "12  loss to real solution:  0.011042061989195105\n",
      "13  epoch, loss:  0.09350719\n",
      "13  epoch, regularization loss:  9.240803\n",
      "13  loss to real solution:  0.010461208738866254\n",
      "14  epoch, loss:  0.08747814\n",
      "14  epoch, regularization loss:  9.438386\n",
      "14  loss to real solution:  0.010256036438527509\n",
      "15  epoch, loss:  0.08190479\n",
      "15  epoch, regularization loss:  9.645272\n",
      "15  loss to real solution:  0.010066795267644334\n",
      "16  epoch, loss:  0.07675436\n",
      "16  epoch, regularization loss:  9.865752\n",
      "16  loss to real solution:  0.009752474707689154\n",
      "17  epoch, loss:  0.07181115\n",
      "17  epoch, regularization loss:  10.099717\n",
      "17  loss to real solution:  0.009581586104955542\n",
      "18  epoch, loss:  0.067444205\n",
      "18  epoch, regularization loss:  10.351049\n",
      "18  loss to real solution:  0.009386925000340897\n",
      "19  epoch, loss:  0.06324735\n",
      "19  epoch, regularization loss:  10.616842\n",
      "19  loss to real solution:  0.009232282537610489\n",
      "20  epoch, loss:  0.05925696\n",
      "20  epoch, regularization loss:  10.898954\n",
      "20  loss to real solution:  0.009084434706361251\n",
      "21  epoch, loss:  0.055752832\n",
      "21  epoch, regularization loss:  11.197468\n",
      "21  loss to real solution:  0.00894303907790895\n",
      "22  epoch, loss:  0.05255723\n",
      "22  epoch, regularization loss:  11.51298\n",
      "22  loss to real solution:  0.008808805543572861\n",
      "23  epoch, loss:  0.049485598\n",
      "23  epoch, regularization loss:  11.84602\n",
      "23  loss to real solution:  0.008680115539224105\n",
      "24  epoch, loss:  0.04667484\n",
      "24  epoch, regularization loss:  12.196909\n",
      "24  loss to real solution:  0.008556126255185563\n",
      "25  epoch, loss:  0.044069316\n",
      "25  epoch, regularization loss:  12.566829\n",
      "25  loss to real solution:  0.008437155682237107\n",
      "26  epoch, loss:  0.041436132\n",
      "26  epoch, regularization loss:  12.959634\n",
      "26  loss to real solution:  0.008329116601140458\n",
      "27  epoch, loss:  0.03913404\n",
      "27  epoch, regularization loss:  13.3730955\n",
      "27  loss to real solution:  0.00822500337997194\n",
      "28  epoch, loss:  0.037027683\n",
      "28  epoch, regularization loss:  13.806201\n",
      "28  loss to real solution:  0.007833776648435936\n",
      "29  epoch, loss:  0.035100825\n",
      "29  epoch, regularization loss:  14.261898\n",
      "29  loss to real solution:  0.007738777573500022\n",
      "30  epoch, loss:  0.03324134\n",
      "30  epoch, regularization loss:  14.741656\n",
      "30  loss to real solution:  0.007648251827154502\n",
      "31  epoch, loss:  0.03153313\n",
      "31  epoch, regularization loss:  15.246162\n",
      "31  loss to real solution:  0.007452559343139136\n",
      "32  epoch, loss:  0.029963054\n",
      "32  epoch, regularization loss:  15.777014\n",
      "32  loss to real solution:  0.0073713253648676515\n",
      "33  epoch, loss:  0.028440028\n",
      "33  epoch, regularization loss:  16.334488\n",
      "33  loss to real solution:  0.0072916482599177\n",
      "34  epoch, loss:  0.027021531\n",
      "34  epoch, regularization loss:  16.923782\n",
      "34  loss to real solution:  0.007217223516265356\n",
      "35  epoch, loss:  0.025634842\n",
      "35  epoch, regularization loss:  17.528105\n",
      "35  loss to real solution:  0.007141603401462042\n",
      "36  epoch, loss:  0.024335653\n",
      "36  epoch, regularization loss:  18.164194\n",
      "36  loss to real solution:  0.007069725266257727\n",
      "37  epoch, loss:  0.02309414\n",
      "37  epoch, regularization loss:  18.831202\n",
      "37  loss to real solution:  0.007000514736930335\n",
      "38  epoch, loss:  0.021976322\n",
      "38  epoch, regularization loss:  19.537205\n",
      "38  loss to real solution:  0.00693731921033045\n",
      "39  epoch, loss:  0.020812832\n",
      "39  epoch, regularization loss:  20.27859\n",
      "39  loss to real solution:  0.0068767993362345336\n",
      "40  epoch, loss:  0.019800335\n",
      "40  epoch, regularization loss:  21.057117\n",
      "40  loss to real solution:  0.006818815341750586\n",
      "41  epoch, loss:  0.01885831\n",
      "41  epoch, regularization loss:  21.874502\n",
      "41  loss to real solution:  0.006763162782947027\n",
      "42  epoch, loss:  0.018003019\n",
      "42  epoch, regularization loss:  22.73229\n",
      "42  loss to real solution:  0.006709280482093298\n",
      "43  epoch, loss:  0.017168928\n",
      "43  epoch, regularization loss:  23.633091\n",
      "43  loss to real solution:  0.00665787654236933\n",
      "44  epoch, loss:  0.016419264\n",
      "44  epoch, regularization loss:  24.578468\n",
      "44  loss to real solution:  0.006608818045417273\n",
      "45  epoch, loss:  0.015719473\n",
      "45  epoch, regularization loss:  25.570406\n",
      "45  loss to real solution:  0.006563254764834845\n",
      "46  epoch, loss:  0.014976436\n",
      "46  epoch, regularization loss:  26.611128\n",
      "46  loss to real solution:  0.006519538334170782\n",
      "47  epoch, loss:  0.01432654\n",
      "47  epoch, regularization loss:  27.703152\n",
      "47  loss to real solution:  0.006477577558318579\n",
      "48  epoch, loss:  0.013696623\n",
      "48  epoch, regularization loss:  28.852104\n",
      "48  loss to real solution:  0.006438722184459174\n",
      "49  epoch, loss:  0.0131161455\n",
      "49  epoch, regularization loss:  30.059395\n",
      "49  loss to real solution:  0.006401767602721656\n",
      "50  epoch, loss:  0.012576218\n",
      "50  epoch, regularization loss:  31.325808\n",
      "50  loss to real solution:  0.006366211047927344\n",
      "51  epoch, loss:  0.012059754\n",
      "51  epoch, regularization loss:  32.653633\n",
      "51  loss to real solution:  0.0063318725140490174\n",
      "52  epoch, loss:  0.011561301\n",
      "52  epoch, regularization loss:  34.045902\n",
      "52  loss to real solution:  0.006298686435977423\n",
      "53  epoch, loss:  0.011121367\n",
      "53  epoch, regularization loss:  35.486984\n",
      "53  loss to real solution:  0.006264091006080115\n",
      "54  epoch, loss:  0.0107167205\n",
      "54  epoch, regularization loss:  37.000755\n",
      "54  loss to real solution:  0.0062311350019373535\n",
      "55  epoch, loss:  0.010308452\n",
      "55  epoch, regularization loss:  38.59101\n",
      "55  loss to real solution:  0.006198895147601568\n",
      "56  epoch, loss:  0.009913813\n",
      "56  epoch, regularization loss:  40.259613\n",
      "56  loss to real solution:  0.006167832485000097\n",
      "57  epoch, loss:  0.009557764\n",
      "57  epoch, regularization loss:  42.010098\n",
      "57  loss to real solution:  0.006137850156585181\n",
      "58  epoch, loss:  0.009230925\n",
      "58  epoch, regularization loss:  43.845856\n",
      "58  loss to real solution:  0.012226855672973942\n",
      "59  epoch, loss:  0.008869727\n",
      "59  epoch, regularization loss:  45.770794\n",
      "59  loss to real solution:  0.012187864102501224\n",
      "60  epoch, loss:  0.008557011\n",
      "60  epoch, regularization loss:  47.788002\n",
      "60  loss to real solution:  0.012150056876320195\n",
      "61  epoch, loss:  0.008291162\n",
      "61  epoch, regularization loss:  49.90381\n",
      "61  loss to real solution:  0.012113577343601536\n",
      "62  epoch, loss:  0.00802238\n",
      "62  epoch, regularization loss:  52.11695\n",
      "62  loss to real solution:  0.012004695864097876\n",
      "63  epoch, loss:  0.007758781\n",
      "63  epoch, regularization loss:  54.43781\n",
      "63  loss to real solution:  0.011969966323749824\n",
      "64  epoch, loss:  0.007535539\n",
      "64  epoch, regularization loss:  56.873104\n",
      "64  loss to real solution:  0.01193611923016767\n",
      "65  epoch, loss:  0.0072473986\n",
      "65  epoch, regularization loss:  59.42612\n",
      "65  loss to real solution:  0.011903214486019416\n",
      "66  epoch, loss:  0.006982428\n",
      "66  epoch, regularization loss:  62.099854\n",
      "66  loss to real solution:  0.011804060181338108\n",
      "67  epoch, loss:  0.006767864\n",
      "67  epoch, regularization loss:  64.8981\n",
      "67  loss to real solution:  0.011772883375841892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68  epoch, loss:  0.006582539\n",
      "68  epoch, regularization loss:  67.833244\n",
      "68  loss to real solution:  0.011743399640280521\n",
      "69  epoch, loss:  0.006410364\n",
      "69  epoch, regularization loss:  70.91165\n",
      "69  loss to real solution:  0.011852542197714987\n",
      "70  epoch, loss:  0.006189526\n",
      "70  epoch, regularization loss:  74.13229\n",
      "70  loss to real solution:  0.01182278279067153\n",
      "71  epoch, loss:  0.0059702927\n",
      "71  epoch, regularization loss:  77.50413\n",
      "71  loss to real solution:  0.011728193307710346\n",
      "72  epoch, loss:  0.0057851705\n",
      "72  epoch, regularization loss:  81.0406\n",
      "72  loss to real solution:  0.01170058860857552\n",
      "73  epoch, loss:  0.0056371004\n",
      "73  epoch, regularization loss:  84.747444\n",
      "73  loss to real solution:  0.011673259878946003\n",
      "74  epoch, loss:  0.005493936\n",
      "74  epoch, regularization loss:  88.63298\n",
      "74  loss to real solution:  0.011589628648199832\n",
      "75  epoch, loss:  0.0053395573\n",
      "75  epoch, regularization loss:  92.69498\n",
      "75  loss to real solution:  0.011563215147890842\n",
      "76  epoch, loss:  0.005168119\n",
      "76  epoch, regularization loss:  96.96363\n",
      "76  loss to real solution:  0.011537982117571628\n",
      "77  epoch, loss:  0.005034649\n",
      "77  epoch, regularization loss:  101.438385\n",
      "77  loss to real solution:  0.011472063236755967\n",
      "78  epoch, loss:  0.0048723635\n",
      "78  epoch, regularization loss:  106.130585\n",
      "78  loss to real solution:  0.011447927825970292\n",
      "79  epoch, loss:  0.0047663176\n",
      "79  epoch, regularization loss:  111.04946\n",
      "79  loss to real solution:  0.011388738306461692\n",
      "80  epoch, loss:  0.004668864\n",
      "80  epoch, regularization loss:  116.2073\n",
      "80  loss to real solution:  0.011365738960205436\n",
      "81  epoch, loss:  0.0045549516\n",
      "81  epoch, regularization loss:  121.61358\n",
      "81  loss to real solution:  0.011343147309719444\n",
      "82  epoch, loss:  0.00442594\n",
      "82  epoch, regularization loss:  127.28084\n",
      "82  loss to real solution:  0.011287660034743791\n",
      "83  epoch, loss:  0.0043207416\n",
      "83  epoch, regularization loss:  133.22394\n",
      "83  loss to real solution:  0.01126605931147719\n",
      "84  epoch, loss:  0.004209596\n",
      "84  epoch, regularization loss:  139.4562\n",
      "84  loss to real solution:  0.011215100531964868\n",
      "85  epoch, loss:  0.004127041\n",
      "85  epoch, regularization loss:  145.9913\n",
      "85  loss to real solution:  0.011174145974854008\n",
      "86  epoch, loss:  0.0040256283\n",
      "86  epoch, regularization loss:  152.84506\n",
      "86  loss to real solution:  0.011140626335504106\n",
      "87  epoch, loss:  0.003948896\n",
      "87  epoch, regularization loss:  160.01106\n",
      "87  loss to real solution:  0.01112242516315227\n",
      "88  epoch, loss:  0.0038763306\n",
      "88  epoch, regularization loss:  167.52592\n",
      "88  loss to real solution:  0.011104438567521625\n",
      "89  epoch, loss:  0.0038022406\n",
      "89  epoch, regularization loss:  175.40573\n",
      "89  loss to real solution:  0.011086598003270678\n",
      "90  epoch, loss:  0.0036931897\n",
      "90  epoch, regularization loss:  183.67084\n",
      "90  loss to real solution:  0.011068741345765642\n",
      "91  epoch, loss:  0.0036250346\n",
      "91  epoch, regularization loss:  192.33676\n",
      "91  loss to real solution:  0.01105082657373195\n",
      "92  epoch, loss:  0.0035440004\n",
      "92  epoch, regularization loss:  201.4231\n",
      "92  loss to real solution:  0.011033067667844348\n",
      "93  epoch, loss:  0.003482208\n",
      "93  epoch, regularization loss:  210.9524\n",
      "93  loss to real solution:  0.011015589499833636\n",
      "94  epoch, loss:  0.0034177392\n",
      "94  epoch, regularization loss:  220.94382\n",
      "94  loss to real solution:  0.01099825170076137\n",
      "95  epoch, loss:  0.0033443053\n",
      "95  epoch, regularization loss:  231.42047\n",
      "95  loss to real solution:  0.01098108645713573\n",
      "96  epoch, loss:  0.0032936498\n",
      "96  epoch, regularization loss:  242.4029\n",
      "96  loss to real solution:  0.01096393283641582\n",
      "97  epoch, loss:  0.0032334574\n",
      "97  epoch, regularization loss:  253.91682\n",
      "97  loss to real solution:  0.01094685610568767\n",
      "98  epoch, loss:  0.0031833495\n",
      "98  epoch, regularization loss:  266.06033\n",
      "98  loss to real solution:  0.010930875802400163\n",
      "99  epoch, loss:  0.0031343643\n",
      "99  epoch, regularization loss:  278.78925\n",
      "99  loss to real solution:  0.010914941692712359\n",
      "100  epoch, loss:  0.0031046148\n",
      "100  epoch, regularization loss:  292.12775\n",
      "100  loss to real solution:  0.01089887883699184\n",
      "101  epoch, loss:  0.0030653737\n",
      "101  epoch, regularization loss:  306.10834\n",
      "101  loss to real solution:  0.010882815981271318\n",
      "102  epoch, loss:  0.0030178933\n",
      "102  epoch, regularization loss:  320.76166\n",
      "102  loss to real solution:  0.010866740608575396\n",
      "103  epoch, loss:  0.0029742492\n",
      "103  epoch, regularization loss:  336.12247\n",
      "103  loss to real solution:  0.010850741231801561\n",
      "104  epoch, loss:  0.0029320344\n",
      "104  epoch, regularization loss:  352.2254\n",
      "104  loss to real solution:  0.010834822619321399\n",
      "105  epoch, loss:  0.0028889345\n",
      "105  epoch, regularization loss:  369.10406\n",
      "105  loss to real solution:  0.010818906689050249\n",
      "106  epoch, loss:  0.0028532643\n",
      "106  epoch, regularization loss:  386.79684\n",
      "106  loss to real solution:  0.010803019667031817\n",
      "107  epoch, loss:  0.0028195134\n",
      "107  epoch, regularization loss:  405.3402\n",
      "107  loss to real solution:  0.010787073338391833\n",
      "108  epoch, loss:  0.0027781862\n",
      "108  epoch, regularization loss:  424.78082\n",
      "108  loss to real solution:  0.010771225059392504\n",
      "109  epoch, loss:  0.002743092\n",
      "109  epoch, regularization loss:  445.16382\n",
      "109  loss to real solution:  0.010755508208634905\n",
      "110  epoch, loss:  0.0027138512\n",
      "110  epoch, regularization loss:  466.5314\n",
      "110  loss to real solution:  0.0107398262265945\n",
      "111  epoch, loss:  0.0026813159\n",
      "111  epoch, regularization loss:  488.93103\n",
      "111  loss to real solution:  0.01072414990699535\n",
      "112  epoch, loss:  0.0026487573\n",
      "112  epoch, regularization loss:  512.40985\n",
      "112  loss to real solution:  0.010653574128874452\n",
      "113  epoch, loss:  0.0026208623\n",
      "113  epoch, regularization loss:  537.0212\n",
      "113  loss to real solution:  0.010638109405764254\n",
      "114  epoch, loss:  0.002587752\n",
      "114  epoch, regularization loss:  562.82153\n",
      "114  loss to real solution:  0.01062267806125513\n",
      "115  epoch, loss:  0.0025539969\n",
      "115  epoch, regularization loss:  589.8437\n",
      "115  loss to real solution:  0.010458647929656442\n",
      "116  epoch, loss:  0.0025203812\n",
      "116  epoch, regularization loss:  618.17914\n",
      "116  loss to real solution:  0.010443132542598184\n",
      "117  epoch, loss:  0.002508838\n",
      "117  epoch, regularization loss:  647.92035\n",
      "117  loss to real solution:  0.010427933954226906\n",
      "118  epoch, loss:  0.0024777907\n",
      "118  epoch, regularization loss:  679.10504\n",
      "118  loss to real solution:  0.01041279228829139\n",
      "119  epoch, loss:  0.0024420144\n",
      "119  epoch, regularization loss:  711.79486\n",
      "119  loss to real solution:  0.010397593699920113\n",
      "120  epoch, loss:  0.002422406\n",
      "120  epoch, regularization loss:  746.2759\n",
      "120  loss to real solution:  0.010385405444133218\n",
      "121  epoch, loss:  0.0023910666\n",
      "121  epoch, regularization loss:  782.41925\n",
      "121  loss to real solution:  0.010372979365813668\n",
      "122  epoch, loss:  0.002367928\n",
      "122  epoch, regularization loss:  820.2997\n",
      "122  loss to real solution:  0.010303895345467664\n",
      "123  epoch, loss:  0.0023486319\n",
      "123  epoch, regularization loss:  860.0021\n",
      "123  loss to real solution:  0.010291186741131879\n",
      "124  epoch, loss:  0.0023245958\n",
      "124  epoch, regularization loss:  901.6159\n",
      "124  loss to real solution:  0.010278311243790724\n",
      "125  epoch, loss:  0.002288376\n",
      "125  epoch, regularization loss:  945.2316\n",
      "125  loss to real solution:  0.010265248289841749\n",
      "126  epoch, loss:  0.0022599788\n",
      "126  epoch, regularization loss:  991.12384\n",
      "126  loss to real solution:  0.01025399761511717\n",
      "127  epoch, loss:  0.0022392822\n",
      "127  epoch, regularization loss:  1039.199\n",
      "127  loss to real solution:  0.010242203644055464\n",
      "128  epoch, loss:  0.0022153112\n",
      "128  epoch, regularization loss:  1089.9816\n",
      "128  loss to real solution:  0.010234954229134657\n",
      "129  epoch, loss:  0.0021934002\n",
      "129  epoch, regularization loss:  1088.7336\n",
      "129  loss to real solution:  0.01022689687325392\n"
     ]
    }
   ],
   "source": [
    "train(the_model, learning_rate=0.001, beta=1, iterations=130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#only save the parameters\n",
    "PATH = './2/test_parameters.pkl'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = 10\n",
    "PATH = './2/test_parameters.pkl'\n",
    "#从文件读取the_model\n",
    "the_model = DeepRitzNet(m)\n",
    "the_model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAD8CAYAAADt2MYTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAYCFDBcsWLAAAPD/AaF4QU+YFLOCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUkAAAD8CAYAAAD6+lbaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRyX7GEfvRQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005254674461320585\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "draw_graph(model)\n",
    "draw_graph1(model)\n",
    "print(cal_loss(model))\n",
    "print(relative_err(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(mod, learning_rate=0.01, beta=1, beta_increase=1.05, iterations=10000, add_gamma=False, gamma=1, gamma_increase=1.02):    \n",
    "\n",
    "    optimizer = torch.optim.Adam(mod.parameters(), lr=learning_rate)\n",
    "    points = np.arange(-1, 1.1, 0.1)\n",
    "    xs, ys = np.meshgrid(points, points)\n",
    "    xs = torch.tensor(xs)\n",
    "    ys = torch.tensor(ys)\n",
    "    xl, yl = xs.size()\n",
    "\n",
    "    for k in range(iterations):\n",
    "        loss = torch.zeros(1)\n",
    "        i1=0\n",
    "        for i in np.arange(1, xl):\n",
    "            for j in np.arange(1, yl):        \n",
    "                x_input = np.zeros(m)\n",
    "                x_input[0] = xs[i, j]\n",
    "                x_input[1] = ys[i, j]\n",
    "\n",
    "                #if (x,y)is not on x轴正半轴\n",
    "                if (abs(x_input[1]) > 0.001 or x_input[0] < 0.001): \n",
    "                    x_input = torch.tensor(x_input).float()\n",
    "                    y = mod(x_input)\n",
    "\n",
    "                    x1 = torch.zeros(m)\n",
    "                    x2 = torch.zeros(m)\n",
    "                    x1[0] = 0.0001\n",
    "                    x2[1] = 0.0001\n",
    "                    x_input_1 = x_input.float() + x1\n",
    "                    x_input_2 = x_input.float() + x2\n",
    "                    x_input_grad_1 = (mod(x_input_1) - y) / 0.0001\n",
    "                    x_input_grad_2 = (mod(x_input_2) - y) / 0.0001\n",
    "                    x_input_2_grad_x = (mod(x_input_1) + mod(x_input_3) - 2 * y) / 0.0001**2\n",
    "                    x_input_2_grad_y = (mod(x_input_2) + mod(x_input_4) - 2 * y) / 0.0001**2\n",
    "\n",
    "                    loss += 0.5 * ((x_input_grad_1) ** 2 + (x_input_grad_2) ** 2)\n",
    "                    i1+=1\n",
    "        if add_gamma:\n",
    "            loss += gamma * (x_input_2_grad_x + x_input_2_grad_y) ** 2\n",
    "        loss/=i1\n",
    "        if gamma < 500:\n",
    "            gamma *= gamma_increase\n",
    "        \n",
    "        regularization = torch.zeros(1)\n",
    "        i2 = 0\n",
    "        for i in range(xl):\n",
    "            for j in range(yl): \n",
    "                if (i==0 or i==xl-1) or (j==0 or j==yl-1) or (i>=xl/2 and j==yl/2+1):\n",
    "                    x_input = np.zeros(m)\n",
    "                    x_input[0] = xs[i, j]\n",
    "                    x_input[1] = ys[i, j]           \n",
    "                    x_input = torch.tensor(x_input).float()\n",
    "                    y = mod(x_input)\n",
    "                    regularization += (y.item()-U_groundtruth(x_input))**2 \n",
    "                    i2 += 1\n",
    "        #print(\"i1:\",i1,\"i2:\",i2)\n",
    "        regularization *= beta / i2\n",
    "        if beta < 500:\n",
    "            beta *= beta_increase\n",
    "        \n",
    "\n",
    "        #print loss\n",
    "        print(k, \" epoch, loss: \", loss.data[0].numpy())\n",
    "        print(k, \" epoch, regularization loss: \", regularization.data[0].numpy())\n",
    "        print(k, \" loss to real solution: \", cal_loss(mod))\n",
    "        if cal_loss(mod) < 0.0001:\n",
    "            break\n",
    "\n",
    "        loss += regularization\n",
    "\n",
    "        #and step the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
