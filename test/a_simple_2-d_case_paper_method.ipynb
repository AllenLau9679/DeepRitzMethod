{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on a simple case\n",
    "Consider the following Possion Equation\n",
    "$$\n",
    "\\begin{cases}\n",
    "    \\Delta u = 1\\qquad &u\\in\\Omega\\\\\n",
    "    u = 0\\qquad &u\\in\\partial\\Omega.\n",
    "\\end{cases}$$\n",
    "Here $\\Omega = \\{(x, y)|x^2+y^2 < 1\\}$\n",
    "\n",
    "The exact solution to this problem is $$u = \\frac{1}{4}(x^2+y^2-1).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from math import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "m = 10\n",
    "learning_rate = 0.01\n",
    "iterations = 400  #default 10000\n",
    "print_every_iter = 100\n",
    "beta = 500 #coefficient for the regularization term in the loss expression, is set to be 1000 in section 3.1\n",
    "n1 = 1000 #number of points in (0,1)^m\n",
    "n2 = 100  #number of points on the border of (0,1)^m\n",
    "n3 = 100  #number of points used for evaluating the error\n",
    "\n",
    "class DeepRitzNet(torch.nn.Module):\n",
    "    def __init__(self, m):\n",
    "        super(DeepRitzNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(m,m)\n",
    "        self.linear2 = torch.nn.Linear(m,m)\n",
    "        self.linear3 = torch.nn.Linear(m,m)\n",
    "        self.linear4 = torch.nn.Linear(m,m)\n",
    "        self.linear5 = torch.nn.Linear(m,m)\n",
    "        self.linear6 = torch.nn.Linear(m,m)\n",
    "        \n",
    "        self.linear7 = torch.nn.Linear(m,1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        y = y + F.relu(self.linear2(F.relu(self.linear1(y))))\n",
    "        y = y + F.relu(self.linear4(F.relu(self.linear3(y))))\n",
    "        y = y + F.relu(self.linear6(F.relu(self.linear5(y))))\n",
    "        output = F.relu(self.linear7(y))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_graph():\n",
    "    points = np.arange(-1, 1, 0.01)\n",
    "    xs, ys = np.meshgrid(points, points)\n",
    "    xs = torch.tensor(xs)\n",
    "    ys = torch.tensor(ys)\n",
    "    xl, yl = xs.size()\n",
    "    z = np.zeros((xl, yl))\n",
    "    for i in range(xl):\n",
    "        for j in range(yl):      \n",
    "            re = np.zeros(m)\n",
    "            re[0] = xs[i, j]\n",
    "            re[1] = ys[i, j]\n",
    "            re = torch.tensor(re)        \n",
    "            z[i, j] = model(re.float()).item() + U_groundtruth(re)\n",
    "    \n",
    "    plt.imshow(z, cmap=cm.hot)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    #plt.savefig(\"loss_1.eps\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_loss():\n",
    "    points = np.arange(-1, 1, 0.1)\n",
    "    xs, ys = np.meshgrid(points, points)\n",
    "    xs = torch.tensor(xs)\n",
    "    ys = torch.tensor(ys)\n",
    "    xl, yl = xs.size()\n",
    "    z = np.zeros((xl, yl))\n",
    "    mmm = 0\n",
    "    for i in range(xl):\n",
    "        for j in range(yl):      \n",
    "            re = np.zeros(m)\n",
    "            re[0] = xs[i, j]\n",
    "            re[1] = ys[i, j]\n",
    "            re = torch.tensor(re)        \n",
    "            z[i, j] = model(re.float()).item() + U_groundtruth(re)\n",
    "            if re[0] ** 2 + re[1] ** 2 < 1 and abs(z[i, j]) > mmm:\n",
    "                mmm += abs(z[i, j])\n",
    "    \n",
    "    return mmm / (xl * yl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#U_groundtruth = 1/4*(x^2+y^2)-1/4\n",
    "#take in a (m,) tensor (x, y, ...)\n",
    "def U_groundtruth(t):\n",
    "    #re = 0\n",
    "    re = (t[0] ** 2 + t[1] ** 2 - 1).item() / 4\n",
    "    return re\n",
    "\n",
    "#turn a (2,) tensor/ndarray to a (m,) tensor\n",
    "def zeropad(x_2, m):\n",
    "    x_10 = torch.zeros(m, )\n",
    "    x_10[0] = x_2[0]\n",
    "    x_10[1] = x_2[1]\n",
    "    return x_10\n",
    "    \n",
    "#sample a (m,) tensor on the border of the unit circle\n",
    "def on_sample(m):\n",
    "    theta = np.random.rand() * 2 * pi\n",
    "    re = np.zeros(m)\n",
    "    re[0] = cos(theta)\n",
    "    re[1] = sin(theta)\n",
    "    re = torch.tensor(re, requires_grad=True)\n",
    "    return re\n",
    "\n",
    "#sample a (m,) tensor in the unit circle\n",
    "def in_sample(m):\n",
    "    r = sqrt(np.random.rand())\n",
    "    theta = np.random.rand() * 2 * pi\n",
    "    re = np.zeros(m)\n",
    "    re[0] = r * cos(theta)\n",
    "    re[1] = r * sin(theta)\n",
    "    re = torch.tensor(re, requires_grad=True)\n",
    "    return re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = DeepRitzNet(m)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "in_error_iter = [] #record the error in Omega every print_every_iter=100 times\n",
    "on_error_iter = [] #record the error on the border of Omega every print_every_iter=100 times\n",
    "\n",
    "mm = 1\n",
    "for i in range(400):\n",
    "    #calculate the loss \n",
    "    loss = torch.zeros(1)\n",
    "    for t in range(n1):\n",
    "        #if I miss out the \".float()\" there will be an error and I don't know why\n",
    "        #It seems to have something to do with the usage of relu()**3 in DeepRitzNet\n",
    "        x_input = in_sample(m)\n",
    "        y = model(x_input.float())\n",
    "        #there will be an error without \"retain_graph=True\" , I don't know why\n",
    "        #y.backward(retain_graph = True)\n",
    "        \n",
    "        x1 = torch.zeros(m)\n",
    "        x2 = torch.zeros(m)\n",
    "        x1[0] = 0.0001\n",
    "        x2[1] = 0.0001\n",
    "        x_input_1 = x_input.float() + x1\n",
    "        x_input_2 = x_input.float() + x2\n",
    "        x_input_grad_1 = (model(x_input_1) - y) / 0.0001\n",
    "        x_input_grad_2 = (model(x_input_2) - y) / 0.0001\n",
    "\n",
    "        loss += 0.5 * ((x_input_grad_1) ** 2 + (x_input_grad_2) ** 2) - y\n",
    "        #loss += 0.5 * ((x_input.grad.float()[0]) ** 2 + (x_input.grad.float()[1]) ** 2) + y\n",
    "    loss /= n1\n",
    "\n",
    "    regularization = torch.zeros(1)\n",
    "    for t in range(n2):\n",
    "        x_input = on_sample(m).float()\n",
    "        y = model(x_input)\n",
    "        regularization += y**2 \n",
    "    regularization *= mm / n2\n",
    "    if mm < 500:\n",
    "        mm = mm * 1.01\n",
    "    \n",
    "    #draw_graph()\n",
    "    print(i, \" epoch, loss: \", loss.data[0].numpy())\n",
    "    print(i, \" epoch, regularization loss: \", regularization.data[0].numpy())\n",
    "    print(i, \" epoch, loss to real solution: \", cal_loss())\n",
    "    \n",
    "    \n",
    "    loss += regularization\n",
    "    \n",
    "    #and step the optimizer\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "        \n",
    "print(\"Traning Completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "# calculate time\n",
    "\n",
    "start = time.time()\n",
    "for i in range(1):\n",
    "    #calculate the loss \n",
    "    loss = torch.zeros(1)\n",
    "    for t in range(n1):\n",
    "        #if I miss out the \".float()\" there will be an error and I don't know why\n",
    "        #It seems to have something to do with the usage of relu()**3 in DeepRitzNet\n",
    "        x_input = in_sample(m)\n",
    "        y = model(x_input.float())\n",
    "        #there will be an error without \"retain_graph=True\" , I don't know why\n",
    "        #y.backward(retain_graph = True)\n",
    "        \n",
    "        x1 = torch.zeros(m)\n",
    "        x2 = torch.zeros(m)\n",
    "        x1[0] = 0.0001\n",
    "        x2[1] = 0.0001\n",
    "        x_input_1 = x_input.float() + x1\n",
    "        x_input_2 = x_input.float() + x2\n",
    "        x_input_grad_1 = (model(x_input_1) - y) / 0.0001\n",
    "        x_input_grad_2 = (model(x_input_2) - y) / 0.0001\n",
    "\n",
    "        loss += 0.5 * ((x_input_grad_1) ** 2 + (x_input_grad_2) ** 2) - y\n",
    "        #loss += 0.5 * ((x_input.grad.float()[0]) ** 2 + (x_input.grad.float()[1]) ** 2) + y\n",
    "    loss /= n1\n",
    "\n",
    "    regularization = torch.zeros(1)\n",
    "    for t in range(n2):\n",
    "        x_input = on_sample(m).float()\n",
    "        y = model(x_input)\n",
    "        regularization += y**2 \n",
    "    regularization *= mm / n2\n",
    "    if mm < 500:\n",
    "        mm = mm * 1.005\n",
    "    \n",
    "    #draw_graph()\n",
    "    print(i, \" epoch, loss: \", loss.data[0].numpy())\n",
    "    print(i, \" epoch, regularization loss: \", regularization.data[0].numpy())\n",
    "    print(i, \" epoch, loss to real solution: \", cal_loss())\n",
    "    \n",
    "    loss += regularization\n",
    "    \n",
    "    #and step the optimizer\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "stop = time.time()\n",
    "print(stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), '1/model.pkl')\n",
    "draw_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cal_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print the error\n",
    "    if((i+1) % print_every_iter == 0):\n",
    "        in_error = 0\n",
    "        on_error = 0\n",
    "        \n",
    "        for t in range(n3):\n",
    "            in_x_test = in_sample(m)\n",
    "            in_error_instant = abs((model(in_x_test.float()) -\n",
    "                                    U_groundtruth(in_x_test.float())).item())\n",
    "            in_error = max(in_error, in_error_instant)\n",
    "            \n",
    "            on_x_test = on_sample(m)\n",
    "            on_error_instant = abs((model(on_x_test.float()) -\n",
    "                                    U_groundtruth(on_x_test.float())).item())\n",
    "            on_error = max(on_error,on_error_instant)\n",
    "            \n",
    "        in_error_iter.append(in_error)\n",
    "        on_error_iter.append(on_error)\n",
    "        \n",
    "        print(\"Error in Omega at the\",i+1,\"th iteration:\",in_error)\n",
    "        print(\"Error on the border of Omega at the\",i+1,\"th iteration:\",on_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python pytorch\n",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
