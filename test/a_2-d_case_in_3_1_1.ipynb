{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on a simple case\n",
    "Consider the following Possion Equation\n",
    "$$\n",
    "\\begin{cases}\n",
    "    -\\Delta u = 1\\qquad &u\\in\\Omega\\\\\n",
    "    u(x) = 0\\qquad &u\\in\\partial\\Omega.\n",
    "\\end{cases}$$\n",
    "Here $\\Omega = (-1,1)\\times(-1,1)\\backslash[0,1)\\times\\{0\\}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from math import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "m = 10\n",
    "learning_rate = 0.01\n",
    "iterations = 400  #default 10000\n",
    "print_every_iter = 100\n",
    "beta = 5 #coefficient for the regularization term in the loss expression, is set to be 1000 in section 3.1\n",
    "n1 = 1000 #number of points in (0,1)^m\n",
    "n2 = 100  #number of points on the border of (0,1)^m\n",
    "n3 = 100  #number of points used for evaluating the error\n",
    "\n",
    "#用DeepRitzNet模拟论文中的 -u\n",
    "class DeepRitzNet(torch.nn.Module):\n",
    "    def __init__(self, m):\n",
    "        super(DeepRitzNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(m,m)\n",
    "        self.linear2 = torch.nn.Linear(m,m)\n",
    "        self.linear3 = torch.nn.Linear(m,m)\n",
    "        self.linear4 = torch.nn.Linear(m,m)\n",
    "        self.linear5 = torch.nn.Linear(m,m)\n",
    "        self.linear6 = torch.nn.Linear(m,m)\n",
    "        \n",
    "        self.linear7 = torch.nn.Linear(m,1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        y = y + F.relu(self.linear2(F.relu(self.linear1(y))))\n",
    "        y = y + F.relu(self.linear4(F.relu(self.linear3(y))))\n",
    "        y = y + F.relu(self.linear6(F.relu(self.linear5(y))))\n",
    "        output = F.relu(self.linear7(y))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_graph():\n",
    "    points = np.arange(-1, 1, 0.01)\n",
    "    xs, ys = np.meshgrid(points, points)\n",
    "    xs = torch.tensor(xs)\n",
    "    ys = torch.tensor(ys)\n",
    "    xl, yl = xs.size()\n",
    "    z = np.zeros((xl, yl))\n",
    "    for i in range(xl):\n",
    "        for j in range(yl):      \n",
    "            re = np.zeros(m)\n",
    "            re[0] = xs[i, j]\n",
    "            re[1] = ys[i, j]\n",
    "            re = torch.tensor(re)        \n",
    "            z[i, j] = model(re.float()).item() #- U_groundtruth(re)\n",
    "            #z[i, j] =  U_groundtruth(re)\n",
    "    \n",
    "    plt.imshow(z, cmap=cm.hot)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    #plt.savefig(\"loss_1.eps\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_loss():\n",
    "    points = np.arange(-1, 1.1, 0.1)\n",
    "    xs, ys = np.meshgrid(points, points)\n",
    "    xs = torch.tensor(xs)\n",
    "    ys = torch.tensor(ys)\n",
    "    xl, yl = xs.size()\n",
    "    z = np.zeros((xl, yl))\n",
    "    mmm = 0\n",
    "    for i in np.arange(1, xl):\n",
    "        for j in np.arange(1, yl):      \n",
    "            re = np.zeros(m)\n",
    "            re[0] = xs[i, j]\n",
    "            re[1] = ys[i, j]\n",
    "            #not on border\n",
    "            if (i<xl/2 or j != yl/2+1):\n",
    "                re = torch.tensor(re)        \n",
    "                z[i, j] = (model(re.float()).item() - U_groundtruth(re))#/ U_groundtruth(re)\n",
    "                if abs(z[i, j]) > mmm:\n",
    "                    mmm += abs(z[i, j])\n",
    "    \n",
    "    return mmm / (xl * yl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#U_groundtruth (r, theta) = sqrt(r) * sin(theta/2)\n",
    "#take in a (m,) tensor (x, y, ...)\n",
    "def U_groundtruth(t):\n",
    "    theta = atan2(t[1].item(), t[0].item()) #+ 2*pi #-pi < atan(·) < pi\n",
    "    re = sqrt(sqrt((t[0] ** 2 + t[1] ** 2).item())) * sin(theta/2)\n",
    "    return re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i1: 390 i2: 80\n",
      "0  epoch, loss:  -0.0051231976\n",
      "0  epoch, regularization loss:  2.201979\n",
      "0 epoch, loss + regularization:  2.1968557834625244\n",
      "i1: 390 i2: 80\n",
      "1  epoch, loss:  -0.0013018325\n",
      "1  epoch, regularization loss:  0.5860268\n",
      "1 epoch, loss + regularization:  0.5847249627113342\n",
      "i1: 390 i2: 80\n",
      "2  epoch, loss:  -4.211321e-06\n",
      "2  epoch, regularization loss:  0.09826857\n",
      "2 epoch, loss + regularization:  0.09826435893774033\n",
      "i1: 390 i2: 80\n",
      "3  epoch, loss:  3.4417906e-05\n",
      "3  epoch, regularization loss:  0.0024763509\n",
      "3 epoch, loss + regularization:  0.0025107688270509243\n",
      "i1: 390 i2: 80\n",
      "4  epoch, loss:  0.0\n",
      "4  epoch, regularization loss:  0.0\n",
      "4 epoch, loss + regularization:  0.0\n",
      "i1: 390 i2: 80\n",
      "5  epoch, loss:  0.0\n",
      "5  epoch, regularization loss:  0.0\n",
      "5 epoch, loss + regularization:  0.0\n",
      "i1: 390 i2: 80\n",
      "6  epoch, loss:  0.0\n",
      "6  epoch, regularization loss:  0.0\n",
      "6 epoch, loss + regularization:  0.0\n",
      "i1: 390 i2: 80\n",
      "7  epoch, loss:  0.0\n",
      "7  epoch, regularization loss:  0.0\n",
      "7 epoch, loss + regularization:  0.0\n",
      "i1: 390 i2: 80\n",
      "8  epoch, loss:  0.0\n",
      "8  epoch, regularization loss:  0.0\n",
      "8 epoch, loss + regularization:  0.0\n",
      "i1: 390 i2: 80\n",
      "9  epoch, loss:  0.0\n",
      "9  epoch, regularization loss:  0.0\n",
      "9 epoch, loss + regularization:  0.0\n",
      "i1: 390 i2: 80\n",
      "10  epoch, loss:  0.0\n",
      "10  epoch, regularization loss:  0.0\n",
      "10 epoch, loss + regularization:  0.0\n",
      "i1: 390 i2: 80\n",
      "11  epoch, loss:  0.0\n",
      "11  epoch, regularization loss:  0.0\n",
      "11 epoch, loss + regularization:  0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-0cc698676775>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;31m#and step the optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \"\"\"\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train with the grid\n",
    "对权重初始化有高度依赖性\n",
    "\"\"\"\n",
    "\n",
    "model = DeepRitzNet(m)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "in_error_iter = [] #record the error in Omega every print_every_iter=100 times\n",
    "on_error_iter = [] #record the error on the border of Omega every print_every_iter=100 times\n",
    "\n",
    "mm = 500\n",
    "points = np.arange(-1, 1.1, 0.1)\n",
    "xs, ys = np.meshgrid(points, points)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "xl, yl = xs.size()\n",
    "\n",
    "for k in range(10000):\n",
    "    loss = torch.zeros(1)\n",
    "    i1=0\n",
    "    #x_input not on the border of \\Omega\n",
    "    for i in np.arange(1, xl):\n",
    "        for j in np.arange(1, yl):        \n",
    "            x_input = np.zeros(m)\n",
    "            x_input[0] = xs[i, j]\n",
    "            x_input[1] = ys[i, j]\n",
    "            \n",
    "            #if (x,y)is not on x-aris\n",
    "            if (abs(x_input[1]) > 0.001 or x_input[0] < 0.001) : \n",
    "                x_input = torch.tensor(x_input).float()\n",
    "                y = model(x_input)\n",
    "\n",
    "                x1 = torch.zeros(m)\n",
    "                x2 = torch.zeros(m)\n",
    "                x1[0] = 0.0001\n",
    "                x2[1] = 0.0001\n",
    "                x_input_1 = x_input.float() + x1\n",
    "                x_input_2 = x_input.float() + x2\n",
    "                x_input_grad_1 = (model(x_input_1) - y) / 0.0001\n",
    "                x_input_grad_2 = (model(x_input_2) - y) / 0.0001\n",
    "\n",
    "                loss += 0.5 * ((x_input_grad_1) ** 2 + (x_input_grad_2) ** 2) - y.item()\n",
    "                #loss += 0.5 * ((x_input.grad.float()[0]) ** 2 + (x_input.grad.float()[1]) ** 2) + y\n",
    "                i1+=1\n",
    "                \n",
    "    #loss /= (xl * yl)\n",
    "    loss/=i1\n",
    "    \n",
    "    regularization = torch.zeros(1)\n",
    "    i2=0\n",
    "    for i in range(xl):\n",
    "        for j in range(yl): \n",
    "            if (i==0 or i==xl-1) or (j==0 or j==yl-1) or (i>=xl/2 and j==yl/2+1):\n",
    "                x_input = np.zeros(m)\n",
    "                x_input[0] = xs[i, j]\n",
    "                x_input[1] = ys[i, j]           \n",
    "                x_input = torch.tensor(x_input).float()\n",
    "                y = model(x_input)\n",
    "                regularization += y.item()**2 \n",
    "                i2 += 1\n",
    "    print(\"i1:\",i1,\"i2:\",i2)\n",
    "    regularization *= mm / i2\n",
    "    #if mm < 500:\n",
    "        #mm = mm * 1.05\n",
    "        \n",
    "    #print loss\n",
    "    print(k, \" epoch, loss: \", loss.data[0].numpy())\n",
    "    print(k, \" epoch, regularization loss: \", regularization.data[0].numpy())\n",
    "    print(k, \"epoch, loss + regularization: \", (loss+regularization).item())\n",
    "    '''\n",
    "    print(k, \" loss to real solution: \", cal_loss())\n",
    "    if cal_loss() < 0.0001:\n",
    "        break\n",
    "    '''\n",
    "    loss += regularization\n",
    "    \n",
    "    #and step the optimizer\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUkAAAD8CAYAAAD6+lbaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIO0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate time for grid method\n",
    "start = time.time()\n",
    "for k in range(10):\n",
    "    loss = torch.zeros(1)\n",
    "    for i in range(xl):\n",
    "        for j in range(yl):        \n",
    "            x_input = np.zeros(m)\n",
    "            x_input[0] = xs[i, j]\n",
    "            x_input[1] = ys[i, j]\n",
    "            if x_input[0] ** 2 + x_input[1] ** 2 < 1:\n",
    "                x_input = torch.tensor(x_input).float()\n",
    "                y = model(x_input)\n",
    "                \n",
    "                x1 = torch.zeros(m)\n",
    "                x2 = torch.zeros(m)\n",
    "                x1[0] = 0.0001\n",
    "                x2[1] = 0.0001\n",
    "                x_input_1 = x_input.float() + x1\n",
    "                x_input_2 = x_input.float() + x2\n",
    "                x_input_grad_1 = (model(x_input_1) - y) / 0.0001\n",
    "                x_input_grad_2 = (model(x_input_2) - y) / 0.0001\n",
    "\n",
    "                loss += 0.5 * ((x_input_grad_1) ** 2 + (x_input_grad_2) ** 2) - y\n",
    "                #loss += 0.5 * ((x_input.grad.float()[0]) ** 2 + (x_input.grad.float()[1]) ** 2) + y\n",
    "                \n",
    "    loss /= (xl * yl)\n",
    "    \n",
    "    regularization = torch.zeros(1)\n",
    "    for t in range(n2):\n",
    "        theta = t / n2 * (2 * pi)\n",
    "        x_input = np.zeros(m)\n",
    "        x_input[0] = cos(theta)\n",
    "        x_input[1] = sin(theta)\n",
    "        x_input = torch.tensor(x_input).float()\n",
    "        y = model(x_input)\n",
    "        regularization += y**2 \n",
    "    regularization *= mm / n2\n",
    "    if mm < 500:\n",
    "        mm = mm * 1.01\n",
    "        \n",
    "    #print loss\n",
    "    print(k, \" epoch, loss: \", loss.data[0].numpy())\n",
    "    print(k, \" epoch, regularization loss: \", regularization.data[0].numpy())\n",
    "    print(k, \" loss to real solution: \", cal_loss())\n",
    "    if cal_loss() < 0.0001:\n",
    "        break\n",
    "    \n",
    "    loss += regularization\n",
    "    \n",
    "    #and step the optimizer\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "stop = time.time()\n",
    "print(stop - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
