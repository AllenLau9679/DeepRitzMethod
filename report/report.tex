\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2018

\usepackage[preprint]{nips_2018}
% to compile a preprint version, e.g., for submission to arXiv, add
% add the [preprint] option:
% \usepackage[preprint]{nips_2018}

% to compile a camera-ready version, add the [final] option, e.g.:
% \usepackage[final]{nips_2018}

% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2018}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
% \usepackage{palatino}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows}
\title{A Brief Report of Deep Ritz Method}

% The \author macro works with any number of authors. There are two
% commands used to separate the names and addresses of multiple
% authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to
% break the lines. Using \AND forces a line break at that point. So,
% if LaTeX puts 3 of 4 authors names on the first line, and the last
% on the second line, try using \AND instead of \And before the third
% author name.

\author{
  Zeyu Jia\\School of Mathematical Science\\Peking University\\ \texttt{1600010603} \\
  \And
  Dinghuai Zhang\\School of Mathematical Science\\Peking University\\ \texttt{1600013525}\\
  \And
  Zhengming Zou\\School of Mathematical Science\\Peking University \\ \texttt{1600011089}
}

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

\begin{abstract}
For long people meet great difficulty when solving numerical partial differential equations (PDEs), especially in high-dimensional conditions. Based on E and Yu's prior work, we explore and improve a way to solve a certain kind of PDE using variational methods and deep neural networks. With residual blocks and stochastic gradient descent, it works well in both low-dimensional and high-dimensional conditions. Besides, our improvement makes the result much better.
\end{abstract}

\section{Introduction}
\par Partial differential equation \cite{evans1998partial} is an important tool to characterize our world mathematically. From physics to chemistry, or from financial to engineering, partial differential equations always play a indispensable role. However, the partial differential equation is always very hard to solve, and most of time it is impossible. So in practice, we often find some ways to simplify the original partial differential equations, and solve it. To achieve this goal, we need to figure out some ways to solve these simplified partial differential equations, or at least, find their approximate solutions.
\par The simplified partial differential equation we are going to discuss in this report is the Poisson equation 
\eqref{poisson}
\begin{equation}\label{poisson}
	\begin{cases}
		\Delta u = f, \qquad\forall x\in\Omega,\\
		u = g, \qquad\forall x\in\partial\Omega.
	\end{cases}
\end{equation}
\par The traditional partial differential solving methods include finite difference method \cite{strikwerda2004finite}, finite volume method \cite{versteeg2007introduction} and finite element method \cite{brenner2007mathematical}. These method are the most commonly used method in solving partial differential equations. And complete theories for these methods, such as consistency, stability and convergence, have been well established. However, these method will become tough, even impossible, to complex functions or high dimension situation. Even though the convergence still holds, the time complexity it guarantees will not permit such enormous calculations. Thus, we need to develop some method to tackle these difficulties.
\par Deep learning \cite{lecun2015deep} has been well developed recently. Benefited from its well approximating ability, flexibility and fine solution to the curse of dimensionality, we have achieved state of art on so many missions, such as classification, object detection and so on. So it is natural to think about a suitable way to use deep learning to solve partial differential equations. \cite{yu2017deep} proposed a method to approximate the solution by a neural network, and use the well-know Ritz method to solve the variational problem. \cite{1707.02568}\cite{weinan2017deep}\cite{beck2017machine} first transfer partial differential equations into backward stochastic differential equations, and then use neural network or other machine learning methods to approximate their solutions.
\par In this report, what we focus on is Deep Ritz Method \cite{yu2017deep}. We derive the theory of this algorithm, give our own interpretations. Besides, we also proposed several novel ideas to this algorithm, including the self-adaptive sampling method and actor-critic self-adaptive sampling method. We also write our own numerical experiments and make some comparison between the original methods and methods we proposed.
\par The plan of this report is as follows: In section 2, we will give a brief introduction of Ritz method, which is the basis of deep Ritz method. The structure of deep Ritz method will be showed in section 3. In section 4, our novelty to the deep Ritz method will be exhibited and illustrated. And finally in section 5, we will show the numerical experiments we done by ourselves and their interpretation.

\section{The Ritz Method}  % 这里我觉得需要一个Ritz Method的引用,Evans或者贾泽宇发的那本数值pde都可以
\par The Ritz method is a method based on the principle of least action to find the approximation to eigenvalue equations that cannot be solved easily (or at all) analytically. Mathematically, the Ritz method can be used to approximate the solution of partial differential equations over a function space. When we want to seek a function $y(x)$that extremizes an integral $I(y(x))$. Suppose that we can approximate $y(x)$ by a linear combination of some linear independent  functions:
\begin{equation}
y(x)=\varphi_0(x)+k_1\varphi_1(x)+...+\varphi_N(x)
\end{equation}
Where $\varphi_{i}(x),i\in\{1,2,...,N\}$  are a set of basis of a function space that we are interested in. In many cases, we use a complete set of functions such as, polynomials or sines and cosines. And $k_i,i\in\{1,2,...,N\}$ are constants to be determined by variational and linear algebraic method. But if we don't just solve the problem in a limited function space, things can be different. 

\par Next we take the homogeneous Dirichlet boundary value problem of the Poisson equation as an example.
\begin{equation}
\left\{
\begin{aligned}
& \Delta u=-f(x),&x\in \Omega \\
 &u=0,&x\in \partial \Omega \\
 \end{aligned}
\right.
\end{equation}
The weak solution corresponding to the principle of least action is
\begin{equation}
\left\{
\begin{aligned}
 \text{find }\ u\in H(\Omega), s.t.\\
 I(u)=\min\limits_{v\in H(\Omega)}I(v)\\
  \end{aligned}
\right.
\end{equation}
Where $H$ is the set of admissible function. And using variational method, we can prove that 
\begin{equation} 
I(v)=\int_\Omega\left(\frac{1}{2}|\nabla v(x)|^2-f(x)v(x)\right)dx. 
\end{equation}
As a matter of fact, if we assume that v is an n-dimensional function, then
\begin{equation}\label{d_I}
\delta I(v)=\int _{\Omega} \left(\frac{\partial v}{\partial x_1}\cdot \delta \frac{\partial v}{\partial x_1}+...+\frac{\partial v}{\partial x_n}\cdot   \delta \frac{\partial v}{\partial x_n}-f(x)\delta      v(x)   \right)dx
\end{equation}
Using the integration by parts method for several items on the left,
\begin{equation}\label{int_by_parts}
\int _{\Omega}\frac{\partial v}{\partial x_1}\cdot \delta \frac{\partial v}{\partial x_1} dx= \frac{\partial v}{\partial x_1}\cdot \delta v\Big|_{\partial \Omega}-\int_{\Omega}\delta v \cdot \frac{\partial^2 v}{\partial x_1 ^2}dx=-\int_{\Omega}\delta v \cdot \frac{\partial^2 v}{\partial x_1 ^2}
\end{equation}
Substituting \eqref{int_by_parts} to \eqref{d_I}
\begin{equation}
\delta I(v)=-\int_{\Omega}\delta v(\Delta v+f(x))dx=0
\end{equation}

\section{Deep Ritz Method with neural networks} %我觉得这里可以引下E老师的
\par Using the Ritz Method mentioned above, it is natural to think of solving pde with deep neural networks. Considering the PDE
\begin{equation}
\Delta u(x)+f(x)=0,\qquad x\in \Omega.
\end {equation}
\par According to Ritz Method, what we need to do is
\begin{equation}
\min\limits_{u\in H}{I(u)},
\end{equation}
where
\begin{equation}\label{I_equ}
I(u)=\int_\Omega\left(\frac{1}{2}|\nabla u(x)|^2-f(x)u(x)\right)dx,
\end{equation}
and $H$ is the set of admissible function. Our main idea is to facilitate the multi-layer neural network approximation function $u(x)$ and use the gradient descent algorithm to get the final result.\\

\subsection{Building trail function}
\par We mainly use a nonlinear transformation $x \to u_{\theta}(x)$ defined by deep neural networks to approximate function $u(x)$. Here $\theta$ denotes all parameters in our model. Similar to ResNet structure, we use several blocks to construct our networks, each block consists of two linear transformation, two activation functions and a residual connection. The $i$-th block can be expressed as 
\begin{equation}
s_i=\phi(W_{i2}\cdot\phi(W_{i1}\cdot s_{i_1}+b_{i1})+b_{i2})+s_{i-1}.\label{res_equ}
\end{equation}

where $s_{i}$ is the output of the $i$-th layer. $W_{i1},W_{i2}\in R^{m\times m},b_{i1},b_{i2}\in R^{m}$ are defined by linear transformation. $\phi$ is the activation function.

\input{architecture}

\par Because our pde involves the Laplace transform, we naturally hope that the second derivative of the function $u(x)$ is not a constant. So we need to pick a proper activation function to ensure the networks' nonlinearity. In our model, we have decided to use 
\begin{equation}
\phi(x)=\max\{x^3,0\} 
\end{equation}

\par The residual connection in (\ref{res_equ})   %这里引ResNet那篇
helps to avoid the gradient vanishing problems.
After several blocks, we use a linear transform to get the final result. The whole network can be expressed as
\begin{equation}
u_{\theta}(x)=a\cdot f_n(x) \circ ...\circ f_1(x)+b
\end{equation}
$f_i(x)$ is the $i$-th block. $a\in R^m,b\in R$ is defined by the final linear transform. Note that the input vector $x$ is not necessarily m-dimensional. In order to handle this mismatch, we can pad $x$ by a zero vector. In our model, we always assume $d<m$.
\par After building our trail function, we are left to minimize the $I(u)$ in (\ref{I_equ})

\subsection{Euler numerical integration method}   %这里可以引用??但不知道引用什么好
\par The first problem we need to solve is to calculate the integral in (\ref{I_equ})
 . For simplicity, define:
 \begin{equation}
 g(x,\theta)=|\nabla u(x)|^2-f(x)u(x)
 \end{equation}
 then the $I(u)$ can be expressed as
 \begin{equation}
 I(u)=\int _{\Omega}g(x,\theta)dx
 \end{equation}
 Obviously, it's impossible to calculate this integral directly. We use Euler numerical integration method to approximate the integral.
 \begin{equation}
 I(u)=L(x,\theta)=\frac{1}{N}\sum\limits_{i=1}^{N}g(x_i,\theta)
 \end{equation}
 Where each $x_i$ corresponds to a data point. Each data point is taken from the grid $[-1,1]\times [-1,1]$ in steps of 0.001.
 \subsection{The stochastic gradient descent algorithm}
 In deep learning, stochastic gradient descent (SGD) is a common method to minimize the loss function. In this problem, we also choose SGD method to minimize $I(u)$, which can be expressed as:
 \begin{equation}
 \theta^{k+1}=\theta^{k}-\eta \nabla_{\theta}\frac{1}{N}\sum\limits_{i=1}^{N}g(x_{i,k},\theta^k)
 \end{equation}
 where $k$ is the number of iterations.$\{x_{i,k}\}$ is the randomly selected data from the grid. In SGD, we only select a small number of data points from the grid at a time. Due to our limited computing capiticy, we should make a compromise  between computing the true gradient and the gradient at a single example. So we choose SGD to compute the gradient against more than one training example (also called a "mini-batch") at each step. In order to optimize our training process, we use the Adam version of SGD.


\section{Our improvements}
\par Along with the footsteps of professor E, we have achieved very good results. Based on the results already available, we want to make further improvements. 

\subsection{L2 regularization}

\subsection{Self-adaptive Sampling}
\par In order to find out the tougher place and enhance the regularization, we use a self-adaptive sampling method here. This idea is similar to adaptive finite element method in chapter 9 of \cite{brenner2007mathematical}, which refines the grid adaptively according to the difficulty of each grid. (this difficulty is described by the value of $f$ given the PDE $\Delta u = f$.) 
\par Here we adopt the self adaptive method on both boundary and interior. Suppose one time the neural network function is $f(x) = \mathrm{NN}(x, \theta_k)$, then we will use the following adaptive method to sample:
\begin{itemize}
	\item For the boundary restrictions, we sample points according to density function $|f(x)|$ where $x$ is on the boundary of $\partial\Omega$.
	\item For interior, we sample uniformly for the variation, and sample according to density function $|\Delta(x) - f(x)|$.
\end{itemize}
\par  According to this method, more points will be sampled at places where the neural network does not fit well, and less points will be sampled at places where the neural network fits well. 

\subsection{Actor-critic Self-adaptive Sampling}
\par From the numerical experiments of self-adaptive sampling method, we find out that the self-adaptive method works better. However, there is one problem is involved in the self-adaptive sampling method. That is, we actually do not know which distribution of sampling is the most suitable way, and can achieve the best regularization effect. In the discussion of the last subsection, we choose the distribution to be proportional to the error between $\Delta(x)$ and $f(x)$. This choice seems plausible, but we cannot make sure that the error we choose in this way is perfect. Hence we introduce the following actor-critic way to sampling.
\par Actor-critic \cite{konda2000actor} is a famous method in reinforcement learning. The core idea is similar to generative adversarial networks (GAN) \cite{goodfellow2014generative}, both of which design two networks, an actor (generative) network and a critic (discriminator). The task of the actor is to generate a distribution or a policy, and the task of the critic is to analyze the difference between the generated distribution and the real distribution.
\par In this settings, we use the actor to generate a distribution which can be used for sampling points for regularization, as we discussed above. The actor is a network whose takes the approximate error as input and output the sampling distribution. As for critic network in our settings, distinguished from \cite{goodfellow2014generative} \cite{konda2000actor}, we use the critic network to test the effectiveness of the sampling distribution generated by the actor. The effectiveness of the sampling can be viewed from the decreasing of variational losses. 
\par For simplicity, we only discussed about the self-adaptive sampling method on the boundary. Suppose the generated distribution is $\pi(\theta_a)$, where $\pi(x, \theta_{a})$ denotes the density at $x$ on $\partial\Omega$. Then the form of actor is
\begin{equation}
	\pi(x) = \phi(|f(x)-0|), \qquad \forall x\in\partial\Omega,
\end{equation}
where $|f(x) - 0|$ is the approximate error on the boundary.
\par As for the critic network, its purpose is to judge the effect of distribution the actor generated. To reduce the effect of randomness, we do not use random sampling points to train this network and use uniform grids instead. In this way, we can obtain the loss to real solutions. (we always train our neural networks with PDEs with real solutions) Compares with deep Ritz method, we also try some numerical methods, such as finite difference method or finite element method. In these method, theories of convergence guarantee the convergence speed of simple solutions, but these theories fail when the functions are rather complicated. Hence it is suitable to use the solutions of these numerical methods to train the neural network. The whole process can be viewed in algorithm 
\ref{ac-algorithm} and figure \ref{ac-figure}
\begin{algorithm}
	\caption{Actor-critic Self-adaptive Training}
	\label{ac-algorithm}
	\begin{algorithmic}[1]
		\State\textbf{Input} Domain $\Omega$, $m, t$.
		\State Generate some rather simple functions $f_1, f_{2}, \cdots, f_{m}$ defined on $\Omega$. And find the solutions $w_{1}, \cdots, w_{m}$ to corresponding Possion equations.
		\State Solve these partial differential equations finite difference method or finite element method with different grid sizes. And obtain approximate solutions $v_{1}^{j}, \cdots, v_{m}^{j}, 1\le j\le t$
		\State For each $1\le i\le m$, find $t$ solutions $u_{i}^{1}, \cdots, u_{i}^{t}$.
		\State Use the current actor network parameter $\theta_{a}$ to generate distributions for $u_{i}^{1}, \cdots, u_{i}^{t}$.
		\State Train the original network with these distribution to obtain $u_{i}'^{1}, \cdots, u_{i}'^{t}$.
		\State Put $u_{i}'^{j}$ and $w_{i}$ into the critic network with parameter $\theta_{c}$, and obtain the loss $\mathcal{L}_{i}^{j}$.
		\State Put $v_{i}^{j}$ and $w_{i}$ into the critic network with parameter $\theta_{c}$, and obtain the loss $L_{i}^{j}$.
		\State Train $\theta_{a}$ to minimize the sum of loss $\mathcal{L}_{i}^{j}$
		\State Train $\theta_{c}$ to discriminate $\mathcal{L}_{i}^{j}$ from $L_{i}^{k}$
 	\end{algorithmic}
\end{algorithm}

\input{ac}

\section{Numerical Results}

\subsection{The Poisson Equation}
\par Considering the Poisson equation:
\begin{equation}
\left\{
\begin{aligned}
 \Delta u=1,& x\in \Omega \\
 u=0, &x\in \partial \Omega \\
 \end{aligned}
\right.
\end{equation}

Here $\Omega =\{(x,y)| x^2+y^2<1\}$.
\par The exact solution to this problem is 
\begin{equation}
u=\frac{1}{4}(x^2+y^2-1)
\end{equation}

\par As described above, we use three blocks (six fully connected layers) and a final linear transform with $m=10$ to build our networks. There is a total of 671 parameters in our model. Considering the boundary condition, we need to make some modifications to our model. We have decided to use a penalty method and the modified function is:
\begin{equation}
I(u)=\int_{\Omega}\left(\frac{1}{2}|\nabla u(x)|^2-u(x)\right)dx+\gamma\int_{\Omega}|\Delta u(x) - 1|^2dx+\beta\int_{\partial \Omega}u(x)^2dx
\end{equation}
Where $\gamma\int_{\Omega}|\Delta u(x) - 1|^2dx$ is the regular term and $\beta\int_{\partial \Omega}u(x)^2dx$ is the penalty item.We choose $\beta=500$ and $\gamma=500$.
\par After 400 iterations, the relative loss of our model is reduced to $1.3\%$. Our training results of Deep Ritz Method is shown in Figure \ref{3.1a}

\begin{figure}[ht]
 	 \centering
 	 \includegraphics[width=0.6\textwidth]{3-1.png} 
	 \caption {The results of Poisson Equation}
	 \label{3.1a}
\end{figure}
As is shown from the figure, the dark color indicates that the absolute error between the numerical solution and the real solution is small, while the light color indicates that the absolute error between the numerical solution and the real solution is relatively large.Deep Ritz method performs well with this problem after 400 iterations.

\par After testing models of different layers, we find that the 3-layers model with 671 parameters performed best on this problem. Our numerical results is shown in Table \ref{different layers of poisson equation}. Too many parameters may lead overfitting, limiting the performance of the networks.

\begin{table}[htbp]
\centering  
\caption{Relative loss of different layers with Poisson Eqaution}
\label{different layers of poisson equation}
\begin{tabular}{ccc} 
	\toprule  %添加表格头部粗线
	Blocks Num&Parameters& Relative Loss\\
	\midrule  %添加表格中横线
	\\3 & 671&1.3\%
	\\
	\\
	\\
	\\
	\bottomrule %添加表格底部粗线
\end{tabular}
\end{table}


\subsection{The poisson equation in high dimension}
As for high dimension equation, our model can also do well. Considering Poisson Equation in higher dimension:
\begin{equation}
\left \{
\begin{aligned}
&-\Delta u =0, &x\in (0,1)^{10} \\
&u(x)=\sum\limits_{k=1}^5x_{2k-1}x_{2k}, &x\in \partial (0,1)^{10}
\end{aligned}
\right.
\end{equation}
The exact solution for this equation is 
\begin{equation}
u(x)=\sum\limits_{k=1}^5x_{2k-1}x_{2k}
\end{equation}
The network we used this time has the same structure as \ref{poisson_in_2d}. We still use three blocks (six fully connected layers) and a final linear transform with m = 10 to build our networks. But there are some differences in the penalty items. This time we let the learning rate increase with the number of iterations, which can lead to a better training results. The learning rate can be expressed as:
\begin{equation}
\beta=\beta_{0}^N
\end{equation}
Where $N$ is the number of iteration. We choose $\beta_0=1.01$.

\subsection{Other Poisson Equation}
\par Considering the following Poisson Equation:
\begin{equation}
\left\{
\begin{aligned}
& \Delta u=0, & x\in \Omega \\
 &u=xy,   &x\in \partial \Omega \\
 \end{aligned}
\right.
\end{equation}

Here $\Omega =\{(x,y)| x^2+y^2<1\}$.
\par The exact solution to this problem is 
\begin{equation}
u=xy
\end{equation}
Compared with the equation in \ref{functional}, there are some differences in the penalty items. This time we let the learning rate increase with the number of iterations, which can lead to a better training results. The learning rate can be expressed as:
\begin{equation}
\beta=\beta_{0}^N
\end{equation}
Where $N$ is the number of iteration.After a few attempts, we choose $\beta_0=1.01$. After 5000 iterations, the relative loss of our model is reduced to 1.4\%. Our training result is shown in Figure \ref{3.2a}
\begin{figure}[ht]
 	 \centering
 	 \includegraphics[width=0.6\textwidth]{3-2.png} 
	 \caption {The results of Poisson Equation}
	 \label{3.2a}
\end{figure}

Same as before, the color depth in the graph reflects the absolute error from the exact value.


\section{Further discussion}

\section{Conclusion and Discussions}

In this project report, we demonstrate that our method is simple but effective when solving a certain series of PDEs. What's more, we can achieve higher accuracy with proper improvement as follows:

\begin{enumerate}
\item
%I don't know how to descibe (\delta u - f) !!
Add a regularization term to punish the norm of lapacian operator. 
\item
Adjust loss coeffecients according to it's shift from  extreme value. We call it \emph{adaptive} method.
\item
Introduce reinforcement learning to adjust the adaptive coeffecients.
\end{enumerate}

While having achieved fairish results, there exist many drawbacks and probable amelioration which we will handle in the future work:

%maybe more ``future work'' can be added here.
\begin{enumerate}
\item
Our method is not robust enough for general application. Sometimes much tuning work is needed for a single PDE.
\item

\item

\end{enumerate}

\section*{Acknowledgement}
%Thanks luyiping

\bibliography{reference}
\bibliographystyle{plain}
\cite{Evans2010Partial}
\cite{Weinan2018The}
\cite{He2016Deep}

\medskip

\small

\end{document}
