\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2018

\usepackage[preprint]{nips_2018}
% to compile a preprint version, e.g., for submission to arXiv, add
% add the [preprint] option:
% \usepackage[preprint]{nips_2018}

% to compile a camera-ready version, add the [final] option, e.g.:
% \usepackage[final]{nips_2018}

% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2018}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{amsmath}
% \usepackage{palatino}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows}
\title{A Brief Report of Deep Ritz Method}

% The \author macro works with any number of authors. There are two
% commands used to separate the names and addresses of multiple
% authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to
% break the lines. Using \AND forces a line break at that point. So,
% if LaTeX puts 3 of 4 authors names on the first line, and the last
% on the second line, try using \AND instead of \And before the third
% author name.

\author{
  Zeyu Jia\\School of Mathematical Science\\Peking University\\ \texttt{1600010603} \\
  \And
  Dinghuai Zhang\\School of Mathematical Science\\Peking University\\ \texttt{1600013525}\\
  \And
  Zhengming Zou\\School of Mathematical Science\\Peking University \\ \texttt{1600011089}
}

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

\begin{abstract}
For long people meet great difficulty when solving numerical partial differential equations (PDEs), especially in high-dimensional conditions. Based on E and Yu's prior work, we explore and improve a way to solve a certain kind of PDE using variational methods and deep neural networks. With residual blocks and stochastic gradient descent, it works well in both low-dimensional and high-dimensional conditions. Besides, our improvement makes the result much better.
\end{abstract}


\section{The Ritz Method}
\par The Ritz method is a method based on the principle of least action to find the approximation to eigenvalue equations that cannot be solved easily (or at all) analytically. Mathematically, the Ritz method can be used to approximate the solution of partial differential equations over a function space. When we want to seek a function $y(x)$that extremizes an integral $I(y(x))$. Suppose that we can approximate $y(x)$ by a linear combination of some linear independent  functions:
\begin{equation}
y(x)=\varphi_0(x)+k_1\varphi_1(x)+...+\varphi_N(x)
\end{equation}
Where $\varphi_{i}(x),i\in\{1,2,...,N\}$  are a set of basis of a function space that we are interested in. In many cases, we use a complete set of functions such as, polynomials or sines and cosines. And $k_i,i\in\{1,2,...,N\}$ are constants to be determined by variational and linear algebraic method. But if we don't just solve the problem in a limited function space, things can be different. 

\par Next we take the homogeneous Dirichlet boundary value problem of the Poisson equation as an example.
\begin{equation}
\left\{
\begin{aligned}
& \Delta u=-f(x),&x\in \Omega \\
 &u=0,&x\in \partial \Omega \\
 \end{aligned}
\right.
\end{equation}
The weak solution corresponding to the principle of least action is
\begin{equation}
\left\{
\begin{aligned}
 \text{find }\ u\in H(\Omega), s.t.\\
 I(u)=\min\limits_{v\in H(\Omega)}I(v)\\
  \end{aligned}
\right.
\end{equation}
Where $H$ is the set of admissible function. And using variational method, we can prove that 
\begin{equation} 
I(v)=\int_\Omega\left(\frac{1}{2}|\nabla v(x)|^2-f(x)v(x)\right)dx. 
\end{equation}
As a matter of fact, if we assume that v is an n-dimensional function, then
\begin{equation}\label{d_I}
\delta I(v)=\int _{\Omega} \left(\frac{\partial v}{\partial x_1}\cdot \delta \frac{\partial v}{\partial x_1}+...+\frac{\partial v}{\partial x_n}\cdot   \delta \frac{\partial v}{\partial x_n}-f(x)\delta      v(x)   \right)dx
\end{equation}
Using the integration by parts method for several items on the left,
\begin{equation}\label{int_by_parts}
\int _{\Omega}\frac{\partial v}{\partial x_1}\cdot \delta \frac{\partial v}{\partial x_1} dx= \frac{\partial v}{\partial x_1}\cdot \delta v\Big|_{\partial \Omega}-\int_{\Omega}\delta v \cdot \frac{\partial^2 v}{\partial x_1 ^2}dx=-\int_{\Omega}\delta v \cdot \frac{\partial^2 v}{\partial x_1 ^2}
\end{equation}
Substituting \eqref{int_by_parts} to \eqref{d_I}
\begin{equation}
\delta I(v)=-\int_{\Omega}\delta v(\Delta v+f(x))dx=0
\end{equation}

\section{Deep Ritz Method with neural networks}
\par Using the Ritz Method mentioned above, it is natural to think of solving pde with deep neural networks. Considering the PDE
\begin{equation}
\Delta u(x)+f(x)=0,\qquad x\in \Omega.
\end {equation}
\par According to Ritz Method, what we need to do is
\begin{equation}
\min\limits_{u\in H}{I(u)},
\end{equation}
where
\begin{equation}\label{I_equ}
I(u)=\int_\Omega\left(\frac{1}{2}|\nabla u(x)|^2-f(x)u(x)\right)dx,
\end{equation}
and $H$ is the set of admissible function. Our main idea is to facilitate the multi-layer neural network approximation function $u(x)$ and use the gradient descent algorithm to get the final result.\\

\subsection{Building trail function}
\par We mainly use a nonlinear transformation $x \to u_{\theta}(x)$ defined by deep neural networks to approximate function $u(x)$. Here $\theta$ denotes all parameters in our model. Similar to ResNet structure, we use several blocks to construct our networks, each block consists of two linear transformation, two activation functions and a residual connection. The $i$-th block can be expressed as 
\begin{equation}
s_i=\phi(W_{i2}\cdot\phi(W_{i1}\cdot s_{i_1}+b_{i1})+b_{i2})+s_{i-1}.\label{res_equ}
\end{equation}
\thispagestyle{empty}
% 流程图定义基本形状
	\begin{figure}
	\caption{Network Structure of Deep Ritz Method}
	\centering
	\tikzstyle{startstop} = [rectangle, rounded corners, minimum width = 2cm, minimum height=1cm,text centered, draw = black, fill=red]
	\tikzstyle{io} = [trapezium, trapezium left angle=70, trapezium right angle=110, minimum width=2cm, minimum height=1cm, text centered, draw=black, fill=purple]
	\tikzstyle{process} = [rectangle, minimum width=3cm, minimum height=0.5cm, text centered, draw=black, fill=pink]
	\tikzstyle{decision} = [diamond, aspect = 3, text centered, draw=black, fill=blue]
	% 箭头形式
	\tikzstyle{arrow} = [->,>=stealth]
	\begin{tikzpicture}[node distance=1cm]
	%定义流程图具体形状
	\node[io,  yshift = -1cm](in1){Input};
	\node[process, below of = in1, yshift = -0.5cm](fc1){FC layer(size m) + activation function};
	\node[process, below of = fc1, yshift = -0.5cm](fc2){FC layer(size m) + activation function};
	\node[decision, right  of = fc1, xshift = 5cm, yshift= -1cm](residual 1){Decision 1 ?};
	\node[process, below of = fc2 , yshift = -0.5cm](fc3){FC layer(size m) + activation function};
	\node[process, below of = fc3, yshift = -0.5cm](fc4){FC layer(size m) + activation function};
	\node[decision, right  of = fc3, xshift = 5cm, yshift= -1cm](residual 2){Decision 1 ?};
	\node[process, below of = fc4, yshift = -0.5cm](fc5){FC layer(size 1) };
	\node[io, below of = fc5, yshift = -0.5cm](out1){Output};
	\coordinate (point1) at (-3cm, -6cm);
	%连接具体形状
	\draw [arrow] (in1) -- (fc1);
	\draw [arrow] (in1) -| node  [right] {} (residual 1);
	\draw [arrow] (fc1) -- (fc2);
	\draw [arrow] (fc2) -- (fc3);
	\draw [arrow] (fc3) -- (fc4);
	\draw [arrow] (fc4) -- (fc5);
	%\draw (residual 1) -- node [above] {Y} (point1);
	\draw [arrow] (residual 1) |- node [right] {} (fc3);
	\draw [arrow] (fc3) -- (out1);
	\end{tikzpicture}
\end{figure}

where $s_{i}$ is the output of the $i$-th layer. $W_{i1},W_{i2}\in R^{m\times m},b_{i1},b_{i2}\in R^{m}$ are defined by linear transformation. $\phi$ is the activation function.

\par Because our pde involves the Laplace transform, we naturally hope that the second derivative of the function $u(x)$ is not a constant. So we need to pick a proper activation function to ensure the networks' nonlinearity. In our model, we have decided to use 
\begin{equation}
\phi(x)=\max\{x^3,0\} 
\end{equation}

\par The residual connection in (\ref{res_equ})
helps to avoid the gradient vanishing problems.
After several blocks, we use a linear transform to get the final result. The whole network can be expressed as
\begin{equation}
u_{\theta}(x)=a\cdot f_n(x) \circ ...\circ f_1(x)+b
\end{equation}
$f_i(x)$ is the $i$-th block. $a\in R^m,b\in R$ is defined by the final linear transform. Note that the input vector $x$ is not necessarily m-dimensional. In order to handle this mismatch, we can pad $x$ by a zero vector. In our model, we always assume $d<m$.
\par After building our trail function, we are left to minimize the $I(u)$ in (\ref{I_equ})

\subsection{Euler numerical integration method}
\par The first problem we need to solve is to calculate the integral in (\ref{I_equ})
 . For simplicity, define:
 \begin{equation}
 g(x,\theta)=|\nabla u(x)|^2-f(x)u(x)
 \end{equation}
 then the $I(u)$ can be expressed as
 \begin{equation}
 I(u)=\int _{\Omega}g(x,\theta)dx
 \end{equation}
 Obviously, it's impossible to calculate this integral directly. We use Euler numerical integration method to approximate the integral.
 \begin{equation}
 I(u)=L(x,\theta)=\frac{1}{N}\sum\limits_{i=1}^{N}g(x_i,\theta)
 \end{equation}
 Where each $x_i$ corresponds to a data point. Each data point is taken from the grid $[-1,1]\times [-1,1]$ in steps of 0.001.
 \subsection{The stochastic gradient descent algorithm}
 In deep learning, stochastic gradient descent (SGD) is a common method to minimize the loss function. In this problem, we also choose SGD method to minimize $I(u)$, which can be expressed as:
 \begin{equation}
 \theta^{k+1}=\theta^{k}-\eta \nabla_{\theta}\frac{1}{N}\sum\limits_{i=1}^{N}g(x_{i,k},\theta^k)
 \end{equation}
 where $k$ is the number of iterations.$\{x_{i,k}\}$ is the randomly selected data from the grid. In SGD, we only select a small number of data points from the grid at a time. Due to our limited computing capiticy, we should make a compromise  between computing the true gradient and the gradient at a single example. So we choose SGD to compute the gradient against more than one training example (also called a "mini-batch") at each step. In order to optimize our training process, we use the Adam version of SGD.


\section{Our improvements}
\par Along with the footsteps of professor E, we have achieved very good results. Based on the results already available, we want to make further improvements. 

\subsection{L2 regularization}

\subsection{Self-adaptive Sampling}
\par In order to find out the tougher place and enhance the regularization, we use a self-adaptive sampling method here. This idea is similar to adaptive finite element method in chapter 9 of \cite{brenner2007mathematical}, which refines the grid adaptively according to the difficulty of each grid. (this difficulty is described by the value of $f$ given the PDE $\Delta u = f$.) 
\par Here we adopt the self adaptive method on both boundary and interior. Suppose one time the neural network function is $f(x) = \mathrm{NN}(x, \theta_k)$, then we will use the following adaptive method to sample:
\begin{itemize}
	\item For the boundary restrictions, we sample points according to density function $|f(x)|$ where $x$ is on the boundary of $\partial\Omega$.
	\item For interior, we sample uniformly for the variation, and sample according to density function $|\Delta(x) - f(x)|$.
\end{itemize}
\par  According to this method, more points will be sampled at places where the neural network does not fit well, and less points will be sampled at places where the neural network fits well. 

\subsection{Actor-critic Self-adaptive Sampling}
\par From the numerical experiments of self-adaptive sampling method, we find out that the self-adaptive method works better. However, there is one problem is involved in the self-adaptive sampling method. That is, we actually do not know which distribution of sampling is the most suitable way, and can achieve the best regularization effect. In the discussion of the last subsection, we choose the distribution to be proportional to the error between $\Delta(x)$ and $f(x)$. This choice seems plausible, but we cannot make sure that the error we choose in this way is perfect. Hence we introduce the following actor-critic way to sampling.
\par Actor-critic \cite{konda2000actor} is a famous method in reinforcement learning. The core idea is similar to generative adversarial networks (GAN) \cite{goodfellow2014generative}, both of which design two networks, an actor (generative) network and a critic (discriminator). The task of the actor is to generate a distribution or a policy, and the task of the critic is to analyze the difference between the generated distribution and the real distribution.
\par In this settings, we use the actor to generate a distribution which can be used for sampling points for regularization, as we discussed above. The actor is a network whose input is the original network's parameters, and the output is the  However, in our settings, distinguished from \cite{goodfellow2014generative} \cite{konda2000actor}, we use the critic network to test the effectiveness of the sampling distribution generated by the actor. The effectiveness of the sampling can be viewed from the decreasing of variational losses. 
\par For simplicity, we only discussed about the self-adaptive sampling method on the boundary. Suppose the generated distribution is $\pi$, where $\pi(x)$ denotes the density and $x\in\partial\Omega$. We also generated a 

\section{Numerical Results}

\subsection{The Poisson Equation}
\par Considering the Poisson equation:
\begin{equation}
\left\{
\begin{aligned}
 \Delta u=1,& x\in \Omega \\
 u=0, &x\in \partial \Omega \\
 \end{aligned}
\right.
\end{equation}

Here $\Omega =\{(x,y)| x^2+y^2<1\}$.
\par The exact solution to this problem is 
\begin{equation}
u=\frac{1}{4}(x^2+y^2-1)
\end{equation}

\par As described above, we use three blocks (six fully connected layers) and a final linear transform with $m=10$ to build our networks. There is a total of 671 parameters in our model. Considering the boundary condition, we need to make some modifications to our model. We have decided to use a penalty method and the modified function is:
\begin{equation}
I(u)=\int_{\Omega}\left(\frac{1}{2}|\nabla u(x)|^2-u(x)\right)dx+\gamma\int_{\Omega}|\Delta u(x) - 1|^2dx+\beta\int_{\partial \Omega}u(x)^2dx
\end{equation}
Where $\gamma\int_{\Omega}|\Delta u(x) - 1|^2dx$ is the regular term and we choose $\gamma=500$ and $\beta\int_{\partial \Omega}u(x)^2dx$ is the penalty item.

\subsection{The poisson equation in high dimension}
As for high dimension equation, our model can also do well. Considering Poisson Equation in higher dimension:
\begin{equation}
\left \{
\begin{aligned}
&-\Delta u =0, &x\in (0,1)^{10} \\
&u(x)=\sum\limits_{k=1}^5x_{2k-1}x_{2k}, &x\in \partial (0,1)^{10}
\end{aligned}
\right.
\end{equation}
The exact solution for this equation is 
\begin{equation}
u(x)=\sum\limits_{k=1}^5x_{2k-1}x_{2k}
\end{equation}
The network we used this time has the same structure as \ref{poisson_in_2d}. We still use three blocks (six fully connected layers) and a final linear transform with m = 10 to build our networks. But there are some differences in the penalty items. This time we let the learning rate increase with the number of iterations, which can lead to a better training results. The learning rate can be expressed as:
\begin{equation}
\beta=\beta_{0}^N
\end{equation}
Where $N$ is the number of iteration. We choose $\beta_0=1.01$.

\subsection{Other Poisson Equation}


\section{Further discussion}

\section{Conclusion and Discussions}

In this project report, we demonstrate that our method is simple but effective when solving a certain series of PDEs. What's more, we can achieve higher accuracy with proper improvement as follows:

\begin{enumerate}
\item
%I don't know how to descibe (\delta u - f) !!
Add a regularization term to punish the norm of lapacian operator. 
\item
Adjust loss coeffecients according to it's shift from  extreme value. We call it \emph{adaptive} method.
\item
Introduce reinforcement learning to adjust the adaptive coeffecients.
\end{enumerate}

While having achieved fairish results, there exist many drawbacks and probable amelioration which we will handle in the future work:

%maybe more ``future work'' can be added here.
\begin{enumerate}
\item
Our method is not robust enough for general application. Sometimes much tuning work is needed for a single PDE.
\item

\item

\end{enumerate}

\section*{Acknowledgement}
%Thanks luyiping

\bibliography{reference}
\bibliographystyle{plain}

\medskip

\small

\end{document}
